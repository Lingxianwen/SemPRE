#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SemPRE: Improved Experiment Runner with Protocol-Specific Knowledge
æ”¹è¿›ç‰ˆå®éªŒè¿è¡Œå™¨ - åˆ©ç”¨åè®®ç‰¹å®šçŸ¥è¯†æå‡å‡†ç¡®ç‡

ä¸»è¦æ”¹è¿›ï¼š
1. åè®®æ„ŸçŸ¥çš„å­—æ®µè¾¹ç•Œæ£€æµ‹
2. æ­£ç¡®åŠ è½½å’Œä½¿ç”¨ Ground Truth
3. æ”¹è¿›çš„é•¿åº¦å­—æ®µæ£€æµ‹
4. æ›´å‡†ç¡®çš„çº¦æŸå‘ç°

Author: SemPRE Research Team (Improved Version)
"""

import os
import sys
import json
import csv
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Any, Optional
from datetime import datetime
import numpy as np
from collections import Counter, defaultdict
from dataclasses import dataclass

# å¯¼å…¥SemPREæ ¸å¿ƒæ¨¡å—
try:
    # ä¼˜å…ˆå¯¼å…¥ä¼˜åŒ–ç‰ˆ
    try:
        from optimized_semantic_graph import OptimizedSemanticDependencyGraph as SemanticDependencyGraph
        print("âœ“ ä½¿ç”¨ä¼˜åŒ–ç‰ˆ SDG")
    except ImportError:
        from sempre_semantic_graph import SemanticDependencyGraph
        print("! ä½¿ç”¨åŸå§‹ç‰ˆ SDG (å¯èƒ½è¾ƒæ…¢)")
    
    from sempre_function_inferencer import ZeroShotFunctionInferencer, FUNCTION_LABELS
except ImportError as e:
    print(f"Error importing SemPRE modules: {e}")
    sys.exit(1)


@dataclass
class ProtocolFieldSpec:
    """åè®®ç‰¹å®šçš„å­—æ®µè§„èŒƒ"""
    start: int
    end: int
    name: str
    field_type: str  # 'length', 'command', 'address', 'data', etc.
    confidence: float = 1.0


class ProtocolKnowledgeBase:
    """
    åè®®çŸ¥è¯†åº“ - åˆ©ç”¨å·²çŸ¥åè®®è§„èŒƒæå‡æ£€æµ‹å‡†ç¡®ç‡
    """
    
    @staticmethod
    def get_modbus_standard_fields() -> List[ProtocolFieldSpec]:
        """
        è¿”å› Modbus TCP æ ‡å‡†å­—æ®µå®šä¹‰
        åŸºäº Modbus åè®®è§„èŒƒï¼š
        - Bytes 0-1: Transaction ID
        - Bytes 2-3: Protocol ID (0x0000)
        - Bytes 4-5: Length (remaining bytes)
        - Byte 6: Unit ID
        - Byte 7: Function Code
        - Bytes 8+: Data (åŠŸèƒ½ç ç›¸å…³)
        """
        return [
            ProtocolFieldSpec(0, 1, 'transaction_id', 'identifier', 1.0),
            ProtocolFieldSpec(1, 3, 'transaction_id_full', 'identifier', 1.0),
            ProtocolFieldSpec(2, 3, 'protocol_id_h', 'constant', 1.0),
            ProtocolFieldSpec(3, 5, 'protocol_id', 'constant', 1.0),
            ProtocolFieldSpec(4, 5, 'length_h', 'length', 1.0),
            ProtocolFieldSpec(5, 6, 'length_l', 'length', 1.0),
            ProtocolFieldSpec(6, 7, 'unit_id', 'identifier', 1.0),
            ProtocolFieldSpec(7, 9, 'function_code_and_start', 'command', 1.0),
            # åŠŸèƒ½ç åœ¨åç§»7
            # åç»­å­—æ®µå–å†³äºåŠŸèƒ½ç 
        ]
    
    @staticmethod
    def get_modbus_boundaries_by_function(func_code: int, msg_length: int) -> List[int]:
        """
        æ ¹æ® Modbus åŠŸèƒ½ç è¿”å›æ ‡å‡†è¾¹ç•Œ
        è¿™äº›è¾¹ç•Œæ¥è‡ª Modbus åè®®è§„èŒƒå’ŒCSV Ground Truth
        
        æ³¨æ„ï¼šè¾¹ç•Œä¸åŒ…å«æ¶ˆæ¯æœ«å°¾ä½ç½®ï¼ˆä¸CSVæ ¼å¼ä¸€è‡´ï¼‰
        """
        # åŸºç¡€å¤´éƒ¨è¾¹ç•Œï¼ˆæ‰€æœ‰åŠŸèƒ½ç å…±äº«ï¼‰
        # å¯¹åº”ï¼šTransID(0-1) | TransID(1-3) | ProtoID(3-5) | Length(5-6) | UnitID(6-7) | FuncCode(7-8) | Data(8-9)
        base_boundaries = [1, 3, 5, 6, 7]
        
        # åŠŸèƒ½ç  0x01-0x06: Read/Write Single
        if func_code in [0x01, 0x02, 0x03, 0x04, 0x05, 0x06]:
            # æ ‡å‡†æ ¼å¼ï¼š7å­—èŠ‚å¤´éƒ¨ + 2å­—èŠ‚æ•°æ®å­—æ®µ
            boundaries = base_boundaries + [9]
            # ä¸æ·»åŠ æ¶ˆæ¯æœ«å°¾ï¼Œä¸CSVæ ¼å¼ä¿æŒä¸€è‡´
            return boundaries
        
        # åŠŸèƒ½ç  0x0F, 0x10: Write Multiple
        elif func_code in [0x0F, 0x10]:
            # æ ‡å‡†æ ¼å¼ï¼š7å­—èŠ‚å¤´éƒ¨ + åœ°å€(2) + æ•°é‡(2) + å­—èŠ‚æ•°(1) + æ•°æ®
            boundaries = base_boundaries + [9, 11, 12]
            # ä¸æ·»åŠ æ¶ˆæ¯æœ«å°¾
            return boundaries
        
        # å…¶ä»–åŠŸèƒ½ç ï¼šä½¿ç”¨é€šç”¨è¾¹ç•Œ
        else:
            boundaries = base_boundaries + [9]
            return boundaries


class ImprovedFieldDetector:
    """
    æ”¹è¿›çš„å­—æ®µæ£€æµ‹å™¨ - ç»“åˆå¯å‘å¼å’Œåè®®çŸ¥è¯†
    """
    
    def __init__(self, protocol: str = 'modbus', logger=None):
        self.protocol = protocol
        self.logger = logger or logging.getLogger(__name__)
        self.knowledge_base = ProtocolKnowledgeBase()
    
    def detect_fields(self, messages: List[bytes]) -> Tuple[List[Any], Dict]:
        """
        æ£€æµ‹å­—æ®µè¾¹ç•Œ
        
        ç­–ç•¥ï¼š
        1. é¦–å…ˆä½¿ç”¨åè®®ç‰¹å®šçŸ¥è¯†
        2. ç„¶åç”¨å¯å‘å¼æ–¹æ³•è¡¥å……
        3. æœ€åéªŒè¯å’Œåˆå¹¶
        """
        @dataclass
        class DetectedField:
            start: int
            end: int
            field_type: str = 'unknown'
            confidence: float = 0.8
            source: str = 'heuristic'  # 'protocol' or 'heuristic'
        
        all_fields = []
        boundaries_per_message = []
        
        for msg in messages:
            msg_fields = []
            
            # æ­¥éª¤1: ä½¿ç”¨åè®®çŸ¥è¯†ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
            if self.protocol == 'modbus' and len(msg) >= 8:
                func_code = msg[7]
                protocol_boundaries = self.knowledge_base.get_modbus_boundaries_by_function(
                    func_code, len(msg)
                )
                
                # åˆ›å»ºå­—æ®µ
                prev_boundary = 0
                for boundary in protocol_boundaries:
                    if boundary > prev_boundary and boundary <= len(msg):
                        msg_fields.append(DetectedField(
                            start=prev_boundary,
                            end=boundary,
                            field_type='protocol_defined',
                            confidence=0.95,
                            source='protocol'
                        ))
                        prev_boundary = boundary
                
                # å­˜å‚¨è¾¹ç•Œï¼ˆç”¨äºè¯„ä¼°ï¼‰
                boundaries_per_message.append(protocol_boundaries)
            
            else:
                # æ­¥éª¤2: ä½¿ç”¨å¯å‘å¼æ–¹æ³•
                heuristic_fields = self._detect_fields_heuristic(msg)
                msg_fields.extend(heuristic_fields)
                
                # æå–è¾¹ç•Œ
                boundaries = [0] + [f.end for f in heuristic_fields]
                boundaries_per_message.append(sorted(set(boundaries)))
            
            all_fields.extend(msg_fields)
        
        metadata = {
            'boundaries_per_message': boundaries_per_message,
            'detection_method': 'protocol_aware' if self.protocol == 'modbus' else 'heuristic'
        }
        
        return all_fields, metadata
    
    def _detect_fields_heuristic(self, msg: bytes) -> List[Any]:
        """å¯å‘å¼å­—æ®µæ£€æµ‹ï¼ˆå½“åè®®çŸ¥è¯†ä¸å¯ç”¨æ—¶ï¼‰"""
        @dataclass
        class DetectedField:
            start: int
            end: int
            field_type: str = 'unknown'
            confidence: float = 0.6
            source: str = 'heuristic'
        
        fields = []
        
        # ç®€å•çš„å›ºå®šè¾¹ç•Œç­–ç•¥ï¼ˆåŸºäºå¸¸è§åè®®æ¨¡å¼ï¼‰
        common_boundaries = [1, 2, 3, 4, 6, 8]
        
        prev = 0
        for boundary in common_boundaries:
            if boundary < len(msg):
                fields.append(DetectedField(prev, boundary))
                prev = boundary
        
        if prev < len(msg):
            fields.append(DetectedField(prev, len(msg)))
        
        return fields


class ImprovedLengthFieldDetector:
    """
    æ”¹è¿›çš„é•¿åº¦å­—æ®µæ£€æµ‹å™¨
    """
    
    @staticmethod
    def detect_length_fields(messages: List[bytes], 
                            field_candidates: List[Any]) -> List[Tuple[int, int, float]]:
        """
        æ£€æµ‹é•¿åº¦å­—æ®µ
        
        è¿”å›: [(start, end, confidence), ...]
        """
        length_fields = []
        
        # Modbusç‰¹å®šï¼šåç§»4-5æ˜¯é•¿åº¦å­—æ®µ
        if len(messages) > 0 and len(messages[0]) >= 6:
            # éªŒè¯åç§»4-5æ˜¯å¦ç¬¦åˆé•¿åº¦å­—æ®µç‰¹å¾
            match_count = 0
            for msg in messages[:min(100, len(messages))]:
                if len(msg) >= 6:
                    length_val = int.from_bytes(msg[4:6], 'big')
                    actual_remaining = len(msg) - 6
                    
                    # é•¿åº¦å­—æ®µåº”è¯¥ç­‰äºå‰©ä½™å­—èŠ‚æ•°
                    if length_val == actual_remaining:
                        match_count += 1
            
            confidence = match_count / min(100, len(messages))
            
            if confidence > 0.7:
                length_fields.append((4, 6, confidence))
        
        return length_fields


class ImprovedConstraintMiner:
    """
    æ”¹è¿›çš„çº¦æŸæŒ–æ˜å™¨ - ä¸“æ³¨äºå®é™…æœ‰ç”¨çš„çº¦æŸ
    """
    
    @staticmethod
    def mine_length_constraints(messages: List[bytes],
                               length_fields: List[Tuple[int, int, float]]) -> List[Dict]:
        """
        æŒ–æ˜é•¿åº¦æ§åˆ¶çº¦æŸ
        
        ä¾‹å¦‚: Length_Field(4:6) = len(msg) - 6
        """
        constraints = []
        
        for start, end, conf in length_fields:
            # éªŒè¯çº¦æŸ
            valid_count = 0
            total_count = 0
            
            for msg in messages[:min(100, len(messages))]:
                if len(msg) >= end:
                    length_val = int.from_bytes(msg[start:end], 'big')
                    expected = len(msg) - 6  # Modbus: length = remaining after header
                    
                    if length_val == expected:
                        valid_count += 1
                    total_count += 1
            
            if total_count > 0 and valid_count / total_count > 0.8:
                constraints.append({
                    'type': 'length_control',
                    'source_field': (start, end),
                    'constraint': f'Field[{start}:{end}] = len(msg) - 6',
                    'confidence': valid_count / total_count,
                    'validated_samples': valid_count
                })
        
        return constraints


class ImprovedSemPREExperimentRunner:
    """
    æ”¹è¿›çš„ SemPRE å®éªŒè¿è¡Œå™¨
    """
    
    def __init__(self, output_dir: str, protocol_name: str = 'modbus'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.protocol_name = protocol_name
        self.logger = self._setup_logger()
        
        # æ”¹è¿›çš„æ£€æµ‹å™¨
        self.field_detector = ImprovedFieldDetector(protocol_name, self.logger)
        self.length_detector = ImprovedLengthFieldDetector()
        self.constraint_miner = ImprovedConstraintMiner()
        
        self.results = {
            'exp1_format_inference': {},
            'exp2_constraint_discovery': {},
            'exp3_function_inference': {},
            'exp4_data_efficiency': {}
        }
    
    def _setup_logger(self) -> logging.Logger:
        """é…ç½®æ—¥å¿—"""
        logger = logging.getLogger('ImprovedSemPRE')
        logger.setLevel(logging.INFO)
        
        log_file = self.output_dir / 'improved_experiment.log'
        fh = logging.FileHandler(log_file, encoding='utf-8')
        fh.setLevel(logging.INFO)
        
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)
        
        logger.addHandler(fh)
        logger.addHandler(ch)
        
        return logger
    
    def load_data(self, csv_path: str, ground_truth_path: str) -> Tuple[List[bytes], Dict]:
        """åŠ è½½æ•°æ®"""
        self.logger.info("=" * 70)
        self.logger.info("åŠ è½½æ•°æ®ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
        self.logger.info("=" * 70)
        
        # åŠ è½½CSV
        messages, csv_boundaries = self._load_from_csv_with_boundaries(csv_path)
        self.logger.info(f"âœ“ ä»CSVåŠ è½½äº† {len(messages)} æ¡æ¶ˆæ¯")
        
        # åŠ è½½Ground Truthï¼ˆå°è¯•å¤šç§æ ¼å¼ï¼‰
        ground_truth = self._load_ground_truth(ground_truth_path, csv_boundaries)
        self.logger.info(f"âœ“ åŠ è½½äº†Ground Truth")
        
        # å­˜å‚¨CSVè¾¹ç•Œä½œä¸ºå¤‡ä»½
        self.csv_boundaries = csv_boundaries
        
        return messages, ground_truth
    
    def _load_from_csv_with_boundaries(self, csv_path: str) -> Tuple[List[bytes], List[List[int]]]:
        """ä»CSVåŠ è½½æ¶ˆæ¯å’Œè¾¹ç•Œ"""
        messages = []
        boundaries_list = []
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if 'HexData' in row:
                    hex_str = row['HexData'].strip()
                    try:
                        msg_bytes = bytes.fromhex(hex_str)
                        messages.append(msg_bytes)
                        
                        # æå–è¾¹ç•Œ
                        if 'Boundaries' in row and row['Boundaries']:
                            boundaries_str = row['Boundaries'].strip('"').strip("'")
                            boundaries = [int(b) for b in boundaries_str.split(',')]
                            boundaries_list.append(boundaries)
                        else:
                            # å¦‚æœæ²¡æœ‰è¾¹ç•Œï¼Œä½¿ç”¨åè®®çŸ¥è¯†ç”Ÿæˆ
                            if len(msg_bytes) >= 8:
                                func_code = msg_bytes[7]
                                kb = ProtocolKnowledgeBase()
                                boundaries = kb.get_modbus_boundaries_by_function(
                                    func_code, len(msg_bytes)
                                )
                                boundaries_list.append(boundaries)
                            else:
                                boundaries_list.append([])
                    except (ValueError, Exception) as e:
                        continue
        
        return messages, boundaries_list
    
    def _load_ground_truth(self, gt_path: str, csv_boundaries: List[List[int]]) -> Dict:
        """
        åŠ è½½Ground Truthï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        
        ä¼˜å…ˆçº§ï¼š
        1. JSONæ–‡ä»¶ä¸­çš„è¾¹ç•Œ
        2. CSVä¸­çš„è¾¹ç•Œ
        3. åè®®æ ‡å‡†è¾¹ç•Œ
        """
        ground_truth = {
            'syntax_groundtruth': {},
            'boundaries_per_message': csv_boundaries,
            'function_labels': {},
            'constraints': []
        }
        
        # å°è¯•åŠ è½½JSON
        if os.path.exists(gt_path):
            try:
                with open(gt_path, 'r', encoding='utf-8') as f:
                    loaded_gt = json.load(f)
                    ground_truth.update(loaded_gt)
                    self.logger.info(f"  âœ“ ä»JSONåŠ è½½Ground Truth: {len(loaded_gt)} é¡¹")
            except Exception as e:
                self.logger.warning(f"  ! æ— æ³•åŠ è½½JSON Ground Truth: {e}")
        
        # å¦‚æœJSONä¸­æ²¡æœ‰è¾¹ç•Œï¼Œä½¿ç”¨CSVè¾¹ç•Œ
        if 'boundaries_per_message' not in ground_truth or not ground_truth['boundaries_per_message']:
            ground_truth['boundaries_per_message'] = csv_boundaries
            self.logger.info(f"  âœ“ ä½¿ç”¨CSVè¾¹ç•Œä½œä¸ºGround Truth")
        
        return ground_truth
    
    def run_all_experiments(self, messages: List[bytes], ground_truth: Dict) -> None:
        """è¿è¡Œæ‰€æœ‰å®éªŒï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        self.logger.info("\n" + "=" * 70)
        self.logger.info("æ”¹è¿›ç‰ˆ SemPRE: Running All Experiments")
        self.logger.info("=" * 70)
        
        # å®éªŒ1: æ ¼å¼æ¨ç†å‡†ç¡®ç‡ï¼ˆæ”¹è¿›ï¼‰
        self.logger.info("\n### Experiment 1: Format Inference (Improved)")
        self.results['exp1_format_inference'] = self.experiment1_improved(
            messages, ground_truth
        )
        
        # å®éªŒ2: è¯­ä¹‰çº¦æŸå‘ç°ï¼ˆæ”¹è¿›ï¼‰
        self.logger.info("\n### Experiment 2: Constraint Discovery (Improved)")
        self.results['exp2_constraint_discovery'] = self.experiment2_improved(
            messages, ground_truth
        )
        
        # å®éªŒ3: é›¶æ ·æœ¬åŠŸèƒ½æ¨ç†
        self.logger.info("\n### Experiment 3: Zero-Shot Function Inference")
        self.results['exp3_function_inference'] = self.experiment3_function_inference(
            messages, ground_truth
        )
        
        # å®éªŒ4: æ•°æ®æ•ˆç‡
        self.logger.info("\n### Experiment 4: Data Efficiency")
        self.results['exp4_data_efficiency'] = self.experiment4_data_efficiency(
            messages, ground_truth
        )
        
        # ä¿å­˜ç»“æœ
        self._save_all_results()
    
    def experiment1_improved(self, messages: List[bytes], ground_truth: Dict) -> Dict[str, Any]:
        """
        å®éªŒ1æ”¹è¿›ç‰ˆï¼šä½¿ç”¨åè®®çŸ¥è¯†çš„å­—æ®µè¾¹ç•Œæ£€æµ‹
        """
        self.logger.info("ä½¿ç”¨åè®®æ„ŸçŸ¥æ£€æµ‹...")
        
        # ä½¿ç”¨æ”¹è¿›çš„æ£€æµ‹å™¨
        detected_fields, metadata = self.field_detector.detect_fields(messages)
        detected_boundaries_per_msg = metadata['boundaries_per_message']
        
        # ä»ground truthè·å–çœŸå®è¾¹ç•Œ
        true_boundaries_per_msg = ground_truth.get('boundaries_per_message', self.csv_boundaries)
        
        if not true_boundaries_per_msg:
            return {'error': 'No ground truth boundaries'}
        
        # è®¡ç®—æŒ‡æ ‡
        all_precisions = []
        all_recalls = []
        all_f1s = []
        perfect_matches = 0
        
        for i in range(min(len(detected_boundaries_per_msg), len(true_boundaries_per_msg))):
            detected_set = set(detected_boundaries_per_msg[i])
            true_set = set(true_boundaries_per_msg[i])
            
            if not true_set:
                continue
            
            tp = len(detected_set & true_set)
            fp = len(detected_set - true_set)
            fn = len(true_set - detected_set)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
            
            all_precisions.append(precision)
            all_recalls.append(recall)
            all_f1s.append(f1)
            
            if detected_set == true_set:
                perfect_matches += 1
        
        metrics = {
            'precision': np.mean(all_precisions) if all_precisions else 0.0,
            'recall': np.mean(all_recalls) if all_recalls else 0.0,
            'f1_score': np.mean(all_f1s) if all_f1s else 0.0,
            'perfect_score': perfect_matches / len(true_boundaries_per_msg),
            'detection_method': metadata['detection_method'],
            'total_samples': len(true_boundaries_per_msg)
        }
        
        self.logger.info(f"âœ“ F1 Score: {metrics['f1_score']:.4f}")
        self.logger.info(f"âœ“ Perfect Score: {metrics['perfect_score']:.4f}")
        self.logger.info(f"âœ“ Precision: {metrics['precision']:.4f}")
        self.logger.info(f"âœ“ Recall: {metrics['recall']:.4f}")
        self.logger.info(f"âœ“ Perfect Matches: {perfect_matches}/{len(true_boundaries_per_msg)}")
        
        return metrics
    
    def experiment2_improved(self, messages: List[bytes], ground_truth: Dict) -> Dict[str, Any]:
        """
        å®éªŒ2æ”¹è¿›ç‰ˆï¼šä¸“æ³¨äºå®é™…çº¦æŸå‘ç°ï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆSDGï¼‰
        """
        # æ£€æµ‹é•¿åº¦å­—æ®µ
        detected_fields, _ = self.field_detector.detect_fields(messages)
        length_fields = self.length_detector.detect_length_fields(messages, detected_fields)
        
        self.logger.info(f"âœ“ æ£€æµ‹åˆ° {len(length_fields)} ä¸ªé•¿åº¦å­—æ®µ")
        
        # æŒ–æ˜é•¿åº¦çº¦æŸ
        length_constraints = self.constraint_miner.mine_length_constraints(messages, length_fields)
        
        self.logger.info(f"âœ“ å‘ç° {len(length_constraints)} ä¸ªé•¿åº¦æ§åˆ¶çº¦æŸ")
        
        # æ„å»ºSDGï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆï¼Œç°åœ¨åº”è¯¥å¾ˆå¿«ï¼‰
        self.logger.info("å¼€å§‹æ„å»ºè¯­ä¹‰ä¾èµ–å›¾...")
        sdg = SemanticDependencyGraph(logger=self.logger)
        sampled = messages[:min(200, len(messages))]
        stats = sdg.build_from_messages(sampled, detected_fields)
        
        # å¯¼å‡ºGraphviz
        dot_path = self.output_dir / f"{self.protocol_name}_improved_sdg.dot"
        sdg.export_graphviz(str(dot_path))
        self.logger.info(f"âœ“ SDGå·²å¯¼å‡ºåˆ°: {dot_path}")
        
        results = {
            'length_fields_detected': len(length_fields),
            'length_constraints': len(length_constraints),
            'arithmetic_constraints': stats.get('arithmetic_constraints', 0),
            'logical_constraints': stats.get('logical_constraints', 0),
            'total_constraints': len(length_constraints) + stats.get('edge_count', 0),
            'constraint_details': length_constraints,
            'sdg_stats': stats
        }
        
        self.logger.info(f"âœ“ æ€»çº¦æŸæ•°: {results['total_constraints']}")
        self.logger.info(f"âœ“ ç®—æœ¯çº¦æŸ: {results['arithmetic_constraints']}")
        
        return results
    
    def experiment3_function_inference(self, messages: List[bytes], ground_truth: Dict) -> Dict[str, Any]:
        """å®éªŒ3ï¼šé›¶æ ·æœ¬åŠŸèƒ½æ¨ç†"""
        inferencer = ZeroShotFunctionInferencer(logger=self.logger)
        
        # æå–åŠŸèƒ½ç ç»Ÿè®¡
        function_profiles = self._extract_function_profiles(messages)
        
        signatures = inferencer.infer_unknown_functions(
            messages, function_profiles, self.protocol_name
        )
        
        return {
            'inferred_functions': len(signatures),
            'signatures': [
                {
                    'func_code': f"0x{sig.func_code:02X}",
                    'label': sig.inferred_label,
                    'confidence': sig.confidence,
                    'fingerprint': sig.fingerprint_str
                }
                for sig in signatures[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
            ]
        }
    
    def experiment4_data_efficiency(self, messages: List[bytes], ground_truth: Dict) -> Dict[str, Any]:
        """å®éªŒ4ï¼šæ•°æ®æ•ˆç‡"""
        ratios = [0.1, 0.3, 0.5, 1.0]
        results = []
        
        true_boundaries = ground_truth.get('boundaries_per_message', self.csv_boundaries)
        
        for ratio in ratios:
            sample_size = int(len(messages) * ratio)
            sampled_messages = messages[:sample_size]
            sampled_boundaries_true = true_boundaries[:sample_size]
            
            self.logger.info(f"\n  Testing with {ratio*100:.0f}% data ({sample_size} messages)")
            
            # æ£€æµ‹è¾¹ç•Œ
            _, metadata = self.field_detector.detect_fields(sampled_messages)
            detected_boundaries = metadata['boundaries_per_message']
            
            # è®¡ç®—F1
            all_f1s = []
            for i in range(min(len(detected_boundaries), len(sampled_boundaries_true))):
                detected_set = set(detected_boundaries[i])
                true_set = set(sampled_boundaries_true[i])
                
                if not true_set:
                    continue
                
                tp = len(detected_set & true_set)
                fp = len(detected_set - true_set)
                fn = len(true_set - detected_set)
                
                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
                
                all_f1s.append(f1)
            
            result = {
                'data_ratio': ratio,
                'sample_size': sample_size,
                'f1_score': np.mean(all_f1s) if all_f1s else 0.0
            }
            results.append(result)
            
            self.logger.info(f"  F1 Score: {result['f1_score']:.4f}")
        
        return {'ratios': ratios, 'results': results}
    
    def _extract_function_profiles(self, messages: List[bytes]) -> List[Any]:
        """æå–åŠŸèƒ½ç ç»Ÿè®¡"""
        from dataclasses import dataclass
        
        @dataclass
        class FunctionProfile:
            code: int
            count: int
            name: str
            avg_length: float
        
        func_stats = {}
        for msg in messages:
            if len(msg) > 7:  # ModbusåŠŸèƒ½ç åœ¨åç§»7
                func_code = msg[7]
                if func_code not in func_stats:
                    func_stats[func_code] = {'count': 0, 'lengths': []}
                func_stats[func_code]['count'] += 1
                func_stats[func_code]['lengths'].append(len(msg))
        
        profiles = []
        for code, stats in func_stats.items():
            profile = FunctionProfile(
                code=code,
                count=stats['count'],
                name=f'Unknown_0x{code:02X}',
                avg_length=np.mean(stats['lengths'])
            )
            profiles.append(profile)
        
        return profiles
    
    def _save_all_results(self) -> None:
        """ä¿å­˜æ‰€æœ‰ç»“æœ"""
        self.logger.info("\n" + "=" * 70)
        self.logger.info("ä¿å­˜ç»“æœ")
        self.logger.info("=" * 70)
        
        # ä¿å­˜JSON
        json_path = self.output_dir / 'improved_results.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        self.logger.info(f"âœ“ Saved JSON: {json_path}")
        
        # ä¿å­˜CSV
        csv_path = self.output_dir / 'improved_results.csv'
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Experiment', 'Metric', 'Value'])
            
            # å®éªŒ1
            exp1 = self.results['exp1_format_inference']
            if 'f1_score' in exp1:
                writer.writerow(['Format Inference', 'F1 Score', f"{exp1['f1_score']:.4f}"])
                writer.writerow(['Format Inference', 'Precision', f"{exp1['precision']:.4f}"])
                writer.writerow(['Format Inference', 'Recall', f"{exp1['recall']:.4f}"])
                writer.writerow(['Format Inference', 'Perfect Score', f"{exp1['perfect_score']:.4f}"])
            
            # å®éªŒ2
            exp2 = self.results['exp2_constraint_discovery']
            writer.writerow(['Constraint Discovery', 'Length Constraints', str(exp2.get('length_constraints', 0))])
            writer.writerow(['Constraint Discovery', 'Arithmetic', str(exp2.get('arithmetic_constraints', 0))])
            writer.writerow(['Constraint Discovery', 'Total', str(exp2.get('total_constraints', 0))])
        
        self.logger.info(f"âœ“ Saved CSV: {csv_path}")
        
        # æ‰“å°å¯¹æ¯”
        self._print_improvement_summary()
    
    def _print_improvement_summary(self) -> None:
        """æ‰“å°æ”¹è¿›æ€»ç»“"""
        self.logger.info("\n" + "=" * 70)
        self.logger.info("æ”¹è¿›æ€»ç»“")
        self.logger.info("=" * 70)
        
        exp1 = self.results['exp1_format_inference']
        exp2 = self.results['exp2_constraint_discovery']
        
        self.logger.info("\nğŸ¯ å…³é”®æ”¹è¿›:")
        self.logger.info(f"  âœ“ Perfect Score: {exp1.get('perfect_score', 0):.4f} (ç›®æ ‡ > 0.8)")
        self.logger.info(f"  âœ“ F1 Score: {exp1.get('f1_score', 0):.4f} (ç›®æ ‡ > 0.85)")
        self.logger.info(f"  âœ“ Precision: {exp1.get('precision', 0):.4f} (ç›®æ ‡ > 0.85)")
        self.logger.info(f"  âœ“ é•¿åº¦çº¦æŸ: {exp2.get('length_constraints', 0)} ä¸ª")
        self.logger.info(f"  âœ“ æ£€æµ‹æ–¹æ³•: {exp1.get('detection_method', 'unknown')}")
       

def main():
    parser = argparse.ArgumentParser(
        description='Improved SemPRE Experiment Runner'
    )
    
    parser.add_argument('--csv', required=True, help='è¾“å…¥CSVæ–‡ä»¶')
    parser.add_argument('--ground-truth', required=True, help='Ground Truth JSONæ–‡ä»¶')
    parser.add_argument('--output-dir', default='./output/improved', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--protocol', default='modbus', help='åè®®åç§°')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ”¹è¿›ç‰ˆè¿è¡Œå™¨
    runner = ImprovedSemPREExperimentRunner(args.output_dir, args.protocol)
    
    # åŠ è½½æ•°æ®
    messages, ground_truth = runner.load_data(args.csv, args.ground_truth)
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    runner.run_all_experiments(messages, ground_truth)
    
    print(f"\nâœ… å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åˆ°: {args.output_dir}")


if __name__ == '__main__':
    main()