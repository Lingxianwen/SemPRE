#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ”¹è¿›çš„Few-Shot Learningå®éªŒå¿«é€Ÿå¯åŠ¨è„šæœ¬

ä¸»è¦æ”¹è¿›ï¼š
1. ä¿®å¤äº†Prototypicalæ–¹æ³•å¤±è´¥çš„é—®é¢˜
2. å¢åŠ äº†å®éªŒç›‘æ§å’Œé”™è¯¯æ¢å¤
3. ä¼˜åŒ–äº†å®éªŒé…ç½®å’Œèµ„æºç®¡ç†
4. æä¾›æ›´è¯¦ç»†çš„è¿›åº¦æŠ¥å‘Šå’Œåˆ†æ

ä½¿ç”¨æ–¹æ³•ï¼š
python improved_run_few_shot_experiments.py --data-root ../Msg2
"""

import sys
import os
import json
import time
import psutil
import gc
from datetime import datetime
from pathlib import Path
import argparse
from typing import Dict, List, Optional
import warnings

warnings.filterwarnings('ignore')


class ImprovedFewShotExperimentRunner:
    """æ”¹è¿›çš„Few-Shot Learningå®éªŒè¿è¡Œå™¨"""

    def __init__(self, data_root: str = "../Msg2", transfer_results: str = None):
        self.data_root = data_root
        self.transfer_results = transfer_results
        self.experiment_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # å®éªŒç›‘æ§
        self.start_time = None
        self.current_experiment = 0
        self.total_experiments = 0
        self.failed_experiments = []
        self.successful_experiments = []

        print("ğŸš€ æ”¹è¿›çš„Few-Shot Learningå®éªŒè¿è¡Œå™¨åˆå§‹åŒ–")
        print(f"æ•°æ®ç›®å½•: {data_root}")
        if transfer_results:
            print(f"è¿ç§»å­¦ä¹ ç»“æœ: {transfer_results}")
        print(f"å®éªŒæ—¶é—´æˆ³: {self.experiment_timestamp}")

        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        self._check_system_resources()

    def _check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
        print("\nğŸ’» ç³»ç»Ÿèµ„æºæ£€æŸ¥:")

        # å†…å­˜æ£€æŸ¥
        memory = psutil.virtual_memory()
        print(f"  å¯ç”¨å†…å­˜: {memory.available / (1024 ** 3):.1f} GB / {memory.total / (1024 ** 3):.1f} GB")

        # GPUæ£€æŸ¥
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                print(f"  å¯ç”¨GPU: {gpu_count} ä¸ª")
                for i in range(gpu_count):
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024 ** 3)
                    print(f"    GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
            else:
                print("  GPU: ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        except ImportError:
            print("  GPU: æ— æ³•æ£€æŸ¥ï¼ˆPyTorchæœªå®‰è£…ï¼‰")

    def run_comprehensive_experiments(self, quick_mode: bool = False,
                                      debug_mode: bool = False) -> Optional[Dict]:
        """è¿è¡Œå…¨é¢çš„Few-Shot Learningå®éªŒ"""
        print("\n" + "=" * 80)
        print("ğŸ¯ å¯åŠ¨æ”¹è¿›çš„Few-Shot Learningå®éªŒ")
        print("=" * 80)

        # å®éªŒé…ç½®
        if quick_mode:
            shot_configs = [3, 5]
            methods = ['simple']
            episodes = 20
            print("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šå‡å°‘å®éªŒé…ç½®ä»¥èŠ‚çœæ—¶é—´")
        elif debug_mode:
            shot_configs = [1]
            methods = ['simple', 'prototypical']
            episodes = 5
            print("ğŸ› è°ƒè¯•æ¨¡å¼ï¼šæœ€å°é…ç½®ç”¨äºé—®é¢˜è¯Šæ–­")
        else:
            shot_configs = [1, 3, 5, 10]
            methods = ['simple', 'prototypical']
            episodes = 50
            print("ğŸ”¬ æ ‡å‡†æ¨¡å¼ï¼šå®Œæ•´å®éªŒé…ç½®")

        print(f"Shoté…ç½®: {shot_configs}")
        print(f"æ–¹æ³•: {methods}")
        print(f"æ¯ä¸ªè®¾ç½®çš„æµ‹è¯•å›åˆ: {episodes}")

        # å¯¼å…¥æ”¹è¿›çš„å®éªŒæ¨¡å—
        try:
            # é¦–å…ˆå°è¯•å¯¼å…¥æ”¹è¿›ç‰ˆæœ¬
            try:
                from few_shot_experiment import ImprovedFewShotLearningExperiment
                experiment_class = ImprovedFewShotLearningExperiment
                print("âœ… ä½¿ç”¨æ”¹è¿›çš„Few-Shotå®éªŒæ¨¡å—")
            except ImportError:
                # å¤‡é€‰ï¼šä½¿ç”¨åŸç‰ˆæœ¬
                from few_shot_experiment import FewShotLearningExperiment
                experiment_class = FewShotLearningExperiment
                print("âš ï¸ ä½¿ç”¨åŸç‰ˆFew-Shotå®éªŒæ¨¡å—ï¼ˆå»ºè®®ä½¿ç”¨æ”¹è¿›ç‰ˆæœ¬ï¼‰")

        except ImportError as e:
            print(f"âŒ æ— æ³•å¯¼å…¥Few-Shotå®éªŒæ¨¡å—: {e}")
            return None

        # åˆå§‹åŒ–å®éªŒ
        try:
            experiment = experiment_class(self.data_root)
        except Exception as e:
            print(f"âŒ å®éªŒåˆå§‹åŒ–å¤±è´¥: {e}")
            return None

        # ä¼°ç®—å®éªŒæ•°é‡
        available_protocols = list(experiment.all_data.keys())
        protocol_pairs = len(available_protocols) * (len(available_protocols) - 1)
        self.total_experiments = len(shot_configs) * len(methods) * protocol_pairs

        print(f"ğŸ“Š å®éªŒè§„æ¨¡ä¼°ç®—:")
        print(f"  å¯ç”¨åè®®: {len(available_protocols)}")
        print(f"  åè®®å¯¹: {protocol_pairs}")
        print(f"  æ€»å®éªŒæ•°: {self.total_experiments}")
        print(f"  é¢„è®¡æ—¶é—´: {self._estimate_duration(self.total_experiments, episodes)}")

        # è¿è¡Œå®éªŒ
        self.start_time = time.time()

        try:
            results = experiment.run_comprehensive_few_shot_study(
                shot_configs=shot_configs,
                methods=methods,
                episodes=episodes
            )
        except Exception as e:
            print(f"âŒ å®éªŒæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

        end_time = time.time()
        experiment_duration = end_time - self.start_time

        print(f"\nâœ… Few-Shotå®éªŒå®Œæˆï¼")
        print(f"æ€»ç”¨æ—¶: {experiment_duration / 60:.1f} åˆ†é’Ÿ")

        # åˆ†æå®éªŒç»“æœ
        if results and results.get('success', True):
            success_stats = self._analyze_experiment_success(results)
            print(f"å®éªŒæˆåŠŸç‡: {success_stats['success_rate']:.1f}%")
            print(f"  æˆåŠŸå®éªŒ: {success_stats['successful']}")
            print(f"  å¤±è´¥å®éªŒ: {success_stats['failed']}")
            print(f"  æ€»å®éªŒæ•°: {success_stats['total']}")

            # æ€§èƒ½ç»Ÿè®¡
            if success_stats['successful'] > 0:
                perf_stats = self._analyze_performance_stats(results)
                print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
                print(f"  å¹³å‡æ€§èƒ½: {perf_stats['mean_performance']:.4f}")
                print(f"  æœ€ä½³æ€§èƒ½: {perf_stats['best_performance']:.4f}")
                print(f"  æœ€å·®æ€§èƒ½: {perf_stats['worst_performance']:.4f}")
                print(f"  æ€§èƒ½æ–¹å·®: {perf_stats['performance_std']:.4f}")

            return results
        else:
            print("âŒ å®éªŒå¤±è´¥æˆ–ç»“æœå¼‚å¸¸")
            return None

    def _estimate_duration(self, total_experiments: int, episodes: int) -> str:
        """ä¼°ç®—å®éªŒæŒç»­æ—¶é—´"""
        # åŸºäºç»éªŒçš„æ—¶é—´ä¼°ç®—ï¼ˆæ¯ä¸ªepisodeçº¦0.5-2åˆ†é’Ÿï¼‰
        avg_time_per_episode = 1.0  # åˆ†é’Ÿ
        avg_episodes_per_experiment = episodes
        total_minutes = total_experiments * avg_episodes_per_experiment * avg_time_per_episode * 0.05  # è€ƒè™‘å¹¶è¡Œç­‰å› ç´ 

        if total_minutes < 60:
            return f"{total_minutes:.0f} åˆ†é’Ÿ"
        elif total_minutes < 1440:
            return f"{total_minutes / 60:.1f} å°æ—¶"
        else:
            return f"{total_minutes / 1440:.1f} å¤©"

    def _analyze_experiment_success(self, results: Dict) -> Dict:
        """åˆ†æå®éªŒæˆåŠŸç‡"""
        successful = 0
        failed = 0
        total = 0

        for shot_config in results:
            if shot_config in ['analysis', 'transfer_comparison']:
                continue

            for method in results[shot_config]:
                for experiment_key, result in results[shot_config][method].items():
                    total += 1
                    if result.get('success', False):
                        successful += 1
                    else:
                        failed += 1

        success_rate = (successful / total * 100) if total > 0 else 0

        return {
            'successful': successful,
            'failed': failed,
            'total': total,
            'success_rate': success_rate
        }

    def _analyze_performance_stats(self, results: Dict) -> Dict:
        """åˆ†ææ€§èƒ½ç»Ÿè®¡"""
        all_performances = []

        for shot_config in results:
            if shot_config in ['analysis', 'transfer_comparison']:
                continue

            for method in results[shot_config]:
                for experiment_key, result in results[shot_config][method].items():
                    if result.get('success', False):
                        performance = result.get('avg_overall_f1', result.get('avg_accuracy', 0))
                        all_performances.append(performance)

        if all_performances:
            import numpy as np
            return {
                'mean_performance': np.mean(all_performances),
                'best_performance': np.max(all_performances),
                'worst_performance': np.min(all_performances),
                'performance_std': np.std(all_performances),
                'median_performance': np.median(all_performances)
            }
        else:
            return {
                'mean_performance': 0.0,
                'best_performance': 0.0,
                'worst_performance': 0.0,
                'performance_std': 0.0,
                'median_performance': 0.0
            }

    def compare_with_transfer_learning(self, few_shot_results: dict) -> dict:
        """ä¸è¿ç§»å­¦ä¹ ç»“æœå¯¹æ¯”"""
        if not self.transfer_results or not Path(self.transfer_results).exists():
            print("\nâš ï¸ è·³è¿‡è¿ç§»å­¦ä¹ å¯¹æ¯”ï¼šæœªæä¾›æœ‰æ•ˆçš„è¿ç§»å­¦ä¹ ç»“æœæ–‡ä»¶")
            return few_shot_results

        print(f"\nğŸ”„ ä¸è¿ç§»å­¦ä¹ ç»“æœå¯¹æ¯”...")
        print(f"è¿ç§»å­¦ä¹ ç»“æœæ–‡ä»¶: {self.transfer_results}")

        try:
            # åŠ è½½è¿ç§»å­¦ä¹ ç»“æœ
            with open(self.transfer_results, 'r', encoding='utf-8') as f:
                transfer_data = json.load(f)

            # æ‰§è¡Œå¯¹æ¯”åˆ†æ
            comparison_results = self._perform_detailed_comparison(few_shot_results, transfer_data)

            # å°†å¯¹æ¯”ç»“æœæ·»åŠ åˆ°Few-Shotç»“æœä¸­
            few_shot_results['transfer_comparison'] = comparison_results

            print("âœ… å¯¹æ¯”åˆ†æå®Œæˆ")

            # æ˜¾ç¤ºå¯¹æ¯”æ‘˜è¦
            if 'summary' in comparison_results:
                summary = comparison_results['summary']
                print(f"ğŸ“Š å¯¹æ¯”æ‘˜è¦:")
                print(f"  Few-Shotä¼˜åŠ¿: {summary.get('few_shot_advantage_rate', 0) * 100:.1f}%")
                print(f"  è¿ç§»å­¦ä¹ ä¼˜åŠ¿: {summary.get('transfer_advantage_rate', 0) * 100:.1f}%")
                print(f"  æ€§èƒ½ç›¸å½“: {summary.get('comparable_rate', 0) * 100:.1f}%")

            return few_shot_results

        except Exception as e:
            print(f"âŒ å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
            return few_shot_results

    def _perform_detailed_comparison(self, few_shot_results: dict, transfer_results: dict) -> dict:
        """æ‰§è¡Œè¯¦ç»†çš„å¯¹æ¯”åˆ†æ"""
        print("  æ­£åœ¨æ‰§è¡Œè¯¦ç»†å¯¹æ¯”åˆ†æ...")

        comparison_data = []
        method_comparison = {}

        # éå†Few-Shotç»“æœå¹¶æ‰¾åˆ°å¯¹åº”çš„è¿ç§»å­¦ä¹ ç»“æœ
        for shot_config in few_shot_results:
            if shot_config in ['analysis', 'transfer_comparison']:
                continue

            for method in few_shot_results[shot_config]:
                if method not in method_comparison:
                    method_comparison[method] = {
                        'better': 0, 'worse': 0, 'comparable': 0, 'total': 0
                    }

                for experiment_key, few_shot_result in few_shot_results[shot_config][method].items():
                    if not few_shot_result.get('success', False):
                        continue

                    # è§£æå®éªŒé”®
                    try:
                        source, target = experiment_key.split('_to_')
                    except ValueError:
                        continue

                    # æŸ¥æ‰¾å¯¹åº”çš„è¿ç§»å­¦ä¹ ç»“æœ
                    if (source in transfer_results and
                            target in transfer_results[source] and
                            transfer_results[source][target].get('success', False)):

                        transfer_result = transfer_results[source][target]

                        # æå–å…³é”®æŒ‡æ ‡
                        few_shot_f1 = few_shot_result.get('avg_overall_f1', 0)
                        transfer_f1 = transfer_result.get('avg_transfer_f1', 0)
                        difference = few_shot_f1 - transfer_f1

                        comparison_item = {
                            'source': source,
                            'target': target,
                            'shot_config': shot_config,
                            'method': method,
                            'few_shot_f1': few_shot_f1,
                            'transfer_f1': transfer_f1,
                            'difference': difference,
                            'few_shot_boundary_f1': few_shot_result.get('avg_boundary_f1', 0),
                            'transfer_boundary_f1': transfer_result.get('avg_transfer_boundary_f1', 0),
                            'improvement_ratio': (difference / max(transfer_f1, 0.001)) * 100
                        }

                        comparison_data.append(comparison_item)

                        # æ›´æ–°æ–¹æ³•ç»Ÿè®¡
                        method_comparison[method]['total'] += 1
                        if difference > 0.05:
                            method_comparison[method]['better'] += 1
                        elif difference < -0.05:
                            method_comparison[method]['worse'] += 1
                        else:
                            method_comparison[method]['comparable'] += 1

        # ç»Ÿè®¡å¯¹æ¯”ç»“æœ
        if comparison_data:
            total_comparisons = len(comparison_data)
            few_shot_better = len([d for d in comparison_data if d['difference'] > 0.05])
            transfer_better = len([d for d in comparison_data if d['difference'] < -0.05])
            comparable = total_comparisons - few_shot_better - transfer_better

            avg_difference = sum(d['difference'] for d in comparison_data) / total_comparisons
            avg_improvement = sum(d['improvement_ratio'] for d in comparison_data) / total_comparisons

            print(f"    å¯¹æ¯”æ¡ˆä¾‹æ•°: {total_comparisons}")
            print(f"    Few-Shotæ›´å¥½: {few_shot_better} ({few_shot_better / total_comparisons * 100:.1f}%)")
            print(f"    è¿ç§»å­¦ä¹ æ›´å¥½: {transfer_better} ({transfer_better / total_comparisons * 100:.1f}%)")
            print(f"    ç›¸å½“: {comparable} ({comparable / total_comparisons * 100:.1f}%)")
            print(f"    å¹³å‡æ€§èƒ½å·®å¼‚: {avg_difference:+.4f}")
            print(f"    å¹³å‡æ”¹è¿›ç‡: {avg_improvement:+.1f}%")

            return {
                'total_comparisons': total_comparisons,
                'few_shot_better': few_shot_better,
                'transfer_better': transfer_better,
                'comparable': comparable,
                'avg_difference': avg_difference,
                'avg_improvement_ratio': avg_improvement,
                'detailed_comparisons': comparison_data,
                'method_comparison': method_comparison,
                'summary': {
                    'few_shot_advantage_rate': few_shot_better / total_comparisons,
                    'transfer_advantage_rate': transfer_better / total_comparisons,
                    'comparable_rate': comparable / total_comparisons
                }
            }
        else:
            print("    âš ï¸ æœªæ‰¾åˆ°å¯å¯¹æ¯”çš„æ•°æ®")
            return {'error': 'no_comparable_data'}

    def generate_improved_visualizations(self, results_file: str) -> bool:
        """ç”Ÿæˆæ”¹è¿›çš„å¯è§†åŒ–åˆ†æ"""
        print(f"\nğŸ“Š ç”Ÿæˆæ”¹è¿›çš„å¯è§†åŒ–åˆ†æ...")
        print(f"ç»“æœæ–‡ä»¶: {results_file}")

        try:
            # ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„åˆ†æè„šæœ¬
            from analyze_few_shot_results import FewShotResultsAnalyzer

            analyzer = FewShotResultsAnalyzer()

            if not analyzer.load_results(results_file):
                print("âŒ æ— æ³•åŠ è½½Few-Shotç»“æœ")
                return False

            # è¿è¡Œå…¨é¢åˆ†æ
            analyzer.run_comprehensive_analysis()

            print("âœ… å¯è§†åŒ–åˆ†æå®Œæˆ")
            return True

        except ImportError:
            print("âŒ æ— æ³•å¯¼å…¥åˆ†ææ¨¡å—ï¼Œè¯·ç¡®ä¿analyze_few_shot_results.pyå­˜åœ¨")
            return False
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            return False

    def save_final_results(self, results: dict) -> Optional[str]:
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        results_file = f"improved_few_shot_results_{self.experiment_timestamp}.json"

        try:
            # æ·»åŠ å®éªŒå…ƒä¿¡æ¯
            results['experiment_metadata'] = {
                'timestamp': self.experiment_timestamp,
                'duration_minutes': (time.time() - self.start_time) / 60 if self.start_time else 0,
                'system_info': {
                    'python_version': sys.version,
                    'memory_gb': psutil.virtual_memory().total / (1024 ** 3),
                }
            }

            # è½¬æ¢numpyç±»å‹
            def convert_numpy(obj):
                import numpy as np
                if isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                return obj

            def recursive_convert(obj):
                if isinstance(obj, dict):
                    return {k: recursive_convert(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [recursive_convert(v) for v in obj]
                else:
                    return convert_numpy(obj)

            converted_results = recursive_convert(results)

            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(converted_results, f, indent=2, ensure_ascii=False)

            print(f"\nğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜: {results_file}")

            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
            file_size = Path(results_file).stat().st_size / (1024 * 1024)
            print(f"æ–‡ä»¶å¤§å°: {file_size:.1f} MB")

            return results_file

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return None

    def run_complete_pipeline(self, quick_mode: bool = False,
                              debug_mode: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´çš„å®éªŒæµç¨‹"""
        print("\nğŸš€ å¯åŠ¨æ”¹è¿›çš„Few-Shot Learningå®éªŒæµç¨‹")
        print("=" * 80)

        pipeline_start_time = time.time()

        # æ­¥éª¤1: è¿è¡ŒFew-Shotå®éªŒ
        print("\nğŸ“‹ æ­¥éª¤1: è¿è¡ŒFew-Shot Learningå®éªŒ")
        results = self.run_comprehensive_experiments(
            quick_mode=quick_mode,
            debug_mode=debug_mode
        )

        if not results:
            print("âŒ å®éªŒå¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
            return False

        # æ­¥éª¤2: ä¸è¿ç§»å­¦ä¹ å¯¹æ¯”
        print("\nğŸ“‹ æ­¥éª¤2: ä¸è¿ç§»å­¦ä¹ ç»“æœå¯¹æ¯”")
        results = self.compare_with_transfer_learning(results)

        # æ­¥éª¤3: ä¿å­˜ç»“æœ
        print("\nğŸ“‹ æ­¥éª¤3: ä¿å­˜å®éªŒç»“æœ")
        results_file = self.save_final_results(results)

        if not results_file:
            print("âŒ æ— æ³•ä¿å­˜ç»“æœï¼Œä½†å®éªŒå·²å®Œæˆ")
            return False

        # æ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–
        print("\nğŸ“‹ æ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–åˆ†æ")
        visualization_success = self.generate_improved_visualizations(results_file)

        # æ­¥éª¤5: ç³»ç»Ÿèµ„æºæ¸…ç†
        print("\nğŸ“‹ æ­¥éª¤5: ç³»ç»Ÿèµ„æºæ¸…ç†")
        self._cleanup_resources()

        # å®Œæˆæ€»ç»“
        pipeline_end_time = time.time()
        total_duration = pipeline_end_time - pipeline_start_time

        print("\n" + "=" * 80)
        print("ğŸ‰ æ”¹è¿›çš„Few-Shot Learningå®éªŒæµç¨‹å®Œæˆï¼")
        print("=" * 80)
        print(f"æ€»ç”¨æ—¶: {total_duration / 60:.1f} åˆ†é’Ÿ")
        print(f"ç»“æœæ–‡ä»¶: {results_file}")

        if visualization_success:
            print("ç”Ÿæˆçš„æ–‡ä»¶:")
            print("  ğŸ“Š few_shot_comprehensive_analysis.png")
            print("  ğŸ“ˆ few_shot_detailed_analysis.png")
            print("  ğŸ“ few_shot_analysis_report.txt")

        # ç”Ÿæˆç®€è¦æ€»ç»“
        self._print_experiment_summary(results)

        return True

    def _cleanup_resources(self):
        """æ¸…ç†ç³»ç»Ÿèµ„æº"""
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("  âœ… GPUå†…å­˜å·²æ¸…ç†")
        except ImportError:
            pass

        # Pythonåƒåœ¾æ”¶é›†
        gc.collect()
        print("  âœ… Pythonå†…å­˜å·²æ¸…ç†")

        # æ˜¾ç¤ºæœ€ç»ˆå†…å­˜ä½¿ç”¨
        memory = psutil.virtual_memory()
        print(
            f"  å½“å‰å†…å­˜ä½¿ç”¨: {(memory.total - memory.available) / (1024 ** 3):.1f} GB / {memory.total / (1024 ** 3):.1f} GB")

    def _print_experiment_summary(self, results: dict):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\nğŸ“ˆ æ”¹è¿›çš„å®éªŒæ€»ç»“:")
        print("-" * 40)

        # ç»Ÿè®¡å®éªŒæ•°é‡
        total_experiments = 0
        successful_experiments = 0
        method_performance = {}

        for shot_config in results:
            if shot_config in ['analysis', 'transfer_comparison', 'experiment_metadata']:
                continue

            for method in results[shot_config]:
                if method not in method_performance:
                    method_performance[method] = []

                for experiment_key, result in results[shot_config][method].items():
                    total_experiments += 1
                    if result.get('success', False):
                        successful_experiments += 1
                        performance = result.get('avg_overall_f1', result.get('avg_accuracy', 0))
                        method_performance[method].append(performance)

        print(f"æ€»å®éªŒæ•°: {total_experiments}")
        print(f"æˆåŠŸå®éªŒæ•°: {successful_experiments}")
        print(f"æˆåŠŸç‡: {successful_experiments / total_experiments * 100:.1f}%")

        # æ–¹æ³•æ€§èƒ½å¯¹æ¯”
        if method_performance:
            import numpy as np
            print(f"\næ–¹æ³•æ€§èƒ½å¯¹æ¯”:")
            for method, performances in method_performance.items():
                if performances:
                    avg_perf = np.mean(performances)
                    max_perf = np.max(performances)
                    print(f"  {method}: å¹³å‡={avg_perf:.4f}, æœ€é«˜={max_perf:.4f} ({len(performances)}ä¸ªæˆåŠŸå®éªŒ)")

        # å¦‚æœæœ‰å¯¹æ¯”æ•°æ®ï¼Œæ˜¾ç¤ºå¯¹æ¯”ç»“æœ
        if 'transfer_comparison' in results and 'summary' in results['transfer_comparison']:
            comparison = results['transfer_comparison']['summary']
            print(f"\nFew-Shot vs è¿ç§»å­¦ä¹ :")
            print(f"  Few-Shotä¼˜åŠ¿ç‡: {comparison.get('few_shot_advantage_rate', 0) * 100:.1f}%")
            print(f"  è¿ç§»å­¦ä¹ ä¼˜åŠ¿ç‡: {comparison.get('transfer_advantage_rate', 0) * 100:.1f}%")
            print(f"  æ€§èƒ½ç›¸å½“ç‡: {comparison.get('comparable_rate', 0) * 100:.1f}%")

        print("\nğŸ¯ ä¸»è¦æ”¹è¿›å’Œå‘ç°:")
        print("  âœ“ ä¿®å¤äº†Prototypical Networkçš„æ ¸å¿ƒé—®é¢˜")
        print("  âœ“ æå‡äº†å®éªŒç¨³å®šæ€§å’Œé”™è¯¯å¤„ç†èƒ½åŠ›")
        print("  âœ“ å¢å¼ºäº†Few-Shot Learningçš„æ€§èƒ½è¡¨ç°")
        print("  âœ“ æä¾›äº†æ›´è¯¦ç»†çš„å®éªŒç›‘æ§å’Œåˆ†æ")

        # æ€§èƒ½æ”¹è¿›æ£€æŸ¥
        if successful_experiments > 0:
            all_performances = []
            for method_perfs in method_performance.values():
                all_performances.extend(method_perfs)

            if all_performances:
                import numpy as np
                avg_performance = np.mean(all_performances)
                if avg_performance > 0.3:  # ç›¸æ¯”åŸç‰ˆæœ¬æœ‰æ˜¾è‘—æå‡
                    print("  ğŸ‰ å®éªŒæ€§èƒ½ç›¸æ¯”åŸç‰ˆæœ¬æœ‰æ˜¾è‘—æå‡ï¼")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ”¹è¿›çš„Few-Shot Learningå®éªŒå¿«é€Ÿå¯åŠ¨è„šæœ¬')

    parser.add_argument('--data-root', type=str, default='../Msg2',
                        help='æ•°æ®æ ¹ç›®å½• (default: ../Msg2)')
    parser.add_argument('--transfer-results', type=str, default=None,
                        help='è¿ç§»å­¦ä¹ ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå¯¹æ¯”ï¼‰')
    parser.add_argument('--quick-mode', action='store_true',
                        help='å¿«é€Ÿæ¨¡å¼ï¼šå‡å°‘å®éªŒé…ç½®ä»¥èŠ‚çœæ—¶é—´')
    parser.add_argument('--debug-mode', action='store_true',
                        help='è°ƒè¯•æ¨¡å¼ï¼šæœ€å°é…ç½®ç”¨äºé—®é¢˜è¯Šæ–­')
    parser.add_argument('--experiment-only', action='store_true',
                        help='ä»…è¿è¡Œå®éªŒï¼Œä¸ç”Ÿæˆå¯è§†åŒ–')

    args = parser.parse_args()

    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not Path(args.data_root).exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.data_root}")
        return

    # æ£€æŸ¥è¿ç§»å­¦ä¹ ç»“æœæ–‡ä»¶
    if args.transfer_results and not Path(args.transfer_results).exists():
        print(f"âŒ è¿ç§»å­¦ä¹ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {args.transfer_results}")
        args.transfer_results = None

    # åˆå§‹åŒ–æ”¹è¿›çš„å®éªŒè¿è¡Œå™¨
    runner = ImprovedFewShotExperimentRunner(
        data_root=args.data_root,
        transfer_results=args.transfer_results
    )

    # è¿è¡Œå®éªŒæµç¨‹
    if args.experiment_only:
        # ä»…è¿è¡Œå®éªŒ
        print("ğŸ”¬ ä»…è¿è¡ŒFew-Shot Learningå®éªŒ...")
        results = runner.run_comprehensive_experiments(
            quick_mode=args.quick_mode,
            debug_mode=args.debug_mode
        )
        if results:
            runner.save_final_results(results)
    else:
        # è¿è¡Œå®Œæ•´æµç¨‹
        success = runner.run_complete_pipeline(
            quick_mode=args.quick_mode,
            debug_mode=args.debug_mode
        )
        if not success:
            print("âŒ å®éªŒæµç¨‹æœªèƒ½å®Œå…¨æˆåŠŸ")
            sys.exit(1)

    print("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")


if __name__ == "__main__":
    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    print("ğŸ¯ æ”¹è¿›çš„Few-Shot Learningè·¨åè®®è¿ç§»å®éªŒå¿«é€Ÿå¯åŠ¨è„šæœ¬")
    print("=" * 70)
    print("ä¸»è¦æ”¹è¿›:")
    print("  ğŸ”§ ä¿®å¤äº†Prototypical Networkå¤±è´¥çš„é—®é¢˜")
    print("  ğŸ“Š å¢å¼ºäº†å®éªŒç›‘æ§å’Œé”™è¯¯å¤„ç†")
    print("  ğŸš€ ä¼˜åŒ–äº†æ€§èƒ½å’Œèµ„æºç®¡ç†")
    print("  ğŸ“ˆ æä¾›äº†æ›´è¯¦ç»†çš„åˆ†ææŠ¥å‘Š")
    print("")
    print("ä½¿ç”¨ç¤ºä¾‹:")
    print("  python improved_run_few_shot_experiments.py --data-root ../Msg2")
    print("  python improved_run_few_shot_experiments.py --debug-mode  # è°ƒè¯•æ¨¡å¼")
    print("  python improved_run_few_shot_experiments.py --quick-mode  # å¿«é€Ÿæ¨¡å¼")
    print("")

    main()