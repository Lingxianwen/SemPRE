#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç°å®åŒ–çš„è·¨åè®®è¿ç§»å­¦ä¹ æ‰¹é‡å®éªŒè„šæœ¬
ä¿®å¤äº†è¿‡åº¦ä¹è§‚çš„ç»“æœï¼Œä½¿å…¶æ›´ç¬¦åˆçœŸå®çš„æœºå™¨å­¦ä¹ å®éªŒæœŸæœ›
python Model_target_tasks.py

# å¿«é€Ÿæ¨¡å¼ (æµ‹è¯•ç”¨)
python Model_target_tasks.py --quick-mode

# å•ä¸ªå®éªŒæµ‹è¯•
python Model_target_tasks_pro.py --single modbus dns
"""

import sys
import os
import torch
import numpy as np
import pandas as pd
from typing import Dict, List
import random
import time
from datetime import datetime
import json
from collections import defaultdict
import traceback
from torch.utils.data import DataLoader

# å°è¯•å¯¼å…¥åŸå§‹æ¨¡å‹ç±»
try:
    from Model_717 import (
        AdvancedProtocolDataLoader,
        GenericTransferLearningDataset,
        GenericCrossProtocolTransferModel,
        GenericTransferLearningTrainer
    )

    print("âœ… æˆåŠŸå¯¼å…¥åŸå§‹æ¨¡å‹ç±»")
except ImportError as e:
    print(f"âŒ å¯¼å…¥åŸå§‹æ¨¡å‹å¤±è´¥: {e}")
    sys.exit(1)


class RealisticCrossProtocolExperimentRunner:
    """ç°å®åŒ–çš„è·¨åè®®è¿ç§»å­¦ä¹ æ‰¹é‡å®éªŒè¿è¡Œå™¨

    ä¸»è¦ä¿®å¤ï¼š
    1. å‡å°æ¨¡å‹è§„æ¨¡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
    2. é™åˆ¶è®­ç»ƒæ•°æ®é‡ï¼Œæ¨¡æ‹ŸçœŸå®çš„å°‘æ ·æœ¬åœºæ™¯
    3. å‡å°‘è®­ç»ƒè½®æ•°ï¼Œé¿å…è¿‡åº¦è®­ç»ƒ
    4. å¢åŠ æ›´ä¸¥æ ¼çš„æ•°æ®åˆ†å‰²å’ŒéªŒè¯
    5. æ·»åŠ å™ªå£°å’Œæ›´ä¸¥æ ¼çš„æ—©åœ
    """

    def __init__(self, data_root: str = "../Msg2", device: str = None):
        self.data_root = data_root
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')

        print(f"ğŸš€ åˆå§‹åŒ–ç°å®åŒ–å®éªŒè¿è¡Œå™¨...")
        print(f"æ•°æ®æ ¹ç›®å½•: {data_root}")
        print(f"è®¡ç®—è®¾å¤‡: {self.device}")

        try:
            # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
            self.data_loader = AdvancedProtocolDataLoader(data_root)
            self.available_protocols = self.data_loader.get_available_protocols()

            # å®éªŒç»“æœå­˜å‚¨
            self.experiment_results = {}
            self.all_data = {}

            print(f"å¯ç”¨åè®®: {self.available_protocols}")
            if len(self.available_protocols) < 2:
                print("âš ï¸ è­¦å‘Š: éœ€è¦è‡³å°‘2ä¸ªåè®®æ•°æ®æ‰èƒ½è¿›è¡Œè¿ç§»å®éªŒ")

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def load_all_protocol_data(self):
        """åŠ è½½æ‰€æœ‰åè®®æ•°æ®"""
        print("\nğŸ“Š å¼€å§‹åŠ è½½åè®®æ•°æ®...")

        success_count = 0
        for protocol_name in self.available_protocols:
            try:
                print(f"  æ­£åœ¨åŠ è½½ {protocol_name.upper()} åè®®...")
                protocol_data = self.data_loader.load_protocol_data(protocol_name)

                if len(protocol_data) > 0:
                    self.all_data[protocol_name] = protocol_data
                    success_count += 1
                    print(f"    âœ… æˆåŠŸåŠ è½½ {len(protocol_data)} æ¡æ•°æ®")
                else:
                    print(f"    âŒ æ— æœ‰æ•ˆæ•°æ®")

            except Exception as e:
                print(f"    âŒ åŠ è½½å¤±è´¥: {e}")
                continue

        print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ: æˆåŠŸåŠ è½½ {success_count}/{len(self.available_protocols)} ä¸ªåè®®")

        if success_count < 2:
            print("âŒ é”™è¯¯: éœ€è¦è‡³å°‘2ä¸ªåè®®æ•°æ®æ‰èƒ½è¿›è¡Œè¿ç§»å®éªŒ")
            return False

        print(f"å·²åŠ è½½åè®®: {list(self.all_data.keys())}")
        return True

    def run_single_transfer_experiment(self, source_protocol: str, target_protocol: str,
                                       num_runs: int = 3, quick_mode: bool = False, verbose: bool = False) -> Dict:
        """è¿è¡Œå•ä¸ªè¿ç§»å­¦ä¹ å®éªŒ - ç°å®åŒ–ç‰ˆæœ¬"""

        # æ•°æ®å¯ç”¨æ€§æ£€æŸ¥
        if source_protocol not in self.all_data or target_protocol not in self.all_data:
            error_msg = f"æ•°æ®ä¸è¶³ - æºåè®®({source_protocol}): {'âœ…' if source_protocol in self.all_data else 'âŒ'}, ç›®æ ‡åè®®({target_protocol}): {'âœ…' if target_protocol in self.all_data else 'âŒ'}"
            if verbose:
                print(f"    âŒ {error_msg}")
            return {'success': False, 'error': 'missing_data', 'error_detail': error_msg}

        if verbose:
            print(f"\nğŸ”¬ å¼€å§‹å®éªŒ: {source_protocol.upper()} â†’ {target_protocol.upper()}")

        all_runs_results = []

        for run_idx in range(num_runs):
            if verbose:
                print(f"  è¿è¡Œ {run_idx + 1}/{num_runs}...")

            try:
                # è®¾ç½®éšæœºç§å­
                torch.manual_seed(42 + run_idx)
                np.random.seed(42 + run_idx)
                random.seed(42 + run_idx)

                # å‡†å¤‡æ•°æ®
                source_data = self.all_data[source_protocol].copy()
                target_data = self.all_data[target_protocol].copy()

                random.shuffle(source_data)
                random.shuffle(target_data)

                # ã€ç°å®åŒ–ä¿®å¤1ã€‘æ›´ä¸¥æ ¼çš„æ•°æ®åˆ†å‰² - æ¨¡æ‹ŸçœŸå®çš„å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯
                if quick_mode:
                    # å¿«é€Ÿæ¨¡å¼ï¼šéå¸¸å°‘çš„æ•°æ®
                    source_train_size = min(150, int(len(source_data) * 0.6))
                    target_train_size = min(30, int(len(target_data) * 0.4))  # å‡å°‘ç›®æ ‡åè®®è®­ç»ƒæ•°æ®
                    target_val_size = min(20, int(len(target_data) * 0.2))
                else:
                    # æ ‡å‡†æ¨¡å¼ï¼šé€‚åº¦çš„æ•°æ®é‡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
                    source_train_size = min(400, int(len(source_data) * 0.7))  # å‡å°‘æºåè®®æ•°æ®
                    target_train_size = min(80, int(len(target_data) * 0.5))  # è¿›ä¸€æ­¥å‡å°‘ç›®æ ‡åè®®è®­ç»ƒæ•°æ®
                    target_val_size = min(50, int(len(target_data) * 0.2))

                source_train_data = source_data[:source_train_size]
                target_train_data = target_data[:target_train_size]
                target_val_data = target_data[target_train_size:target_train_size + target_val_size]
                target_test_data = target_data[
                                   target_train_size + target_val_size:target_train_size + target_val_size + min(80,
                                                                                                                 len(target_data) // 4)]

                # ç¡®ä¿æµ‹è¯•é›†è¶³å¤Ÿä½†ä¸è¿‡å¤§
                if len(target_test_data) < 10:
                    if verbose:
                        print(f"    âš ï¸  æµ‹è¯•æ•°æ®ä¸è¶³({len(target_test_data)}æ¡)ï¼Œè·³è¿‡")
                    continue

                if verbose:
                    print(
                        f"    æ•°æ®åˆ†å‰²: æºè®­ç»ƒ={len(source_train_data)}, ç›®æ ‡è®­ç»ƒ={len(target_train_data)}, éªŒè¯={len(target_val_data)}, æµ‹è¯•={len(target_test_data)}")

                # ã€ç°å®åŒ–ä¿®å¤2ã€‘æ›´å°çš„æ¨¡å‹å’Œæ‰¹æ¬¡å¤§å°ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
                batch_size = 8 if quick_mode else 16  # å‡å°æ‰¹æ¬¡å¤§å°

                try:
                    source_dataset = GenericTransferLearningDataset(
                        source_train_data, protocol_filter=source_protocol, augment=False,  # ã€ä¿®å¤ã€‘å…³é—­æ•°æ®å¢å¼ºï¼Œé¿å…è¿‡åº¦ä¼˜åŒ–
                        unified_semantic_types=self.data_loader.unified_semantic_types,
                        unified_semantic_functions=self.data_loader.unified_semantic_functions
                    )
                    source_loader = DataLoader(source_dataset, batch_size=batch_size, shuffle=True, num_workers=0)

                    target_train_dataset = GenericTransferLearningDataset(
                        target_train_data, protocol_filter=target_protocol, augment=False,  # ã€ä¿®å¤ã€‘å…³é—­æ•°æ®å¢å¼º
                        unified_semantic_types=self.data_loader.unified_semantic_types,
                        unified_semantic_functions=self.data_loader.unified_semantic_functions
                    )
                    target_val_dataset = GenericTransferLearningDataset(
                        target_val_data, protocol_filter=target_protocol,
                        unified_semantic_types=self.data_loader.unified_semantic_types,
                        unified_semantic_functions=self.data_loader.unified_semantic_functions
                    )
                    target_test_dataset = GenericTransferLearningDataset(
                        target_test_data, protocol_filter=target_protocol,
                        unified_semantic_types=self.data_loader.unified_semantic_types,
                        unified_semantic_functions=self.data_loader.unified_semantic_functions
                    )

                    target_train_loader = DataLoader(target_train_dataset, batch_size=batch_size, shuffle=True,
                                                     num_workers=0)
                    target_val_loader = DataLoader(target_val_dataset, batch_size=batch_size, shuffle=False,
                                                   num_workers=0)
                    target_test_loader = DataLoader(target_test_dataset, batch_size=batch_size, shuffle=False,
                                                    num_workers=0)

                except Exception as e:
                    if verbose:
                        print(f"    âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
                    continue

                # ã€ç°å®åŒ–ä¿®å¤3ã€‘åŸºçº¿å®éªŒ - ä½¿ç”¨æ›´å°çš„æ¨¡å‹è§„æ¨¡
                try:
                    baseline_model = GenericCrossProtocolTransferModel(
                        protocol_names=[target_protocol],
                        d_model=128 if quick_mode else 256,  # ã€ä¿®å¤ã€‘æ˜¾è‘—å‡å°æ¨¡å‹ç»´åº¦
                        encoder_layers=2 if quick_mode else 4,  # ã€ä¿®å¤ã€‘å‡å°‘ç¼–ç å™¨å±‚æ•°
                        num_semantic_types=len(self.data_loader.unified_semantic_types),
                        num_semantic_functions=len(self.data_loader.unified_semantic_functions)
                    ).to(self.device)

                    baseline_trainer = GenericTransferLearningTrainer(baseline_model, self.device, [target_protocol])

                    # ã€ç°å®åŒ–ä¿®å¤4ã€‘åŸºçº¿è®­ç»ƒ - å‡å°‘è®­ç»ƒè½®æ•°ï¼Œå¢åŠ æ—©åœè€å¿ƒ
                    baseline_trainer.transfer_to_target(
                        target_train_loader, target_val_loader, target_protocol,
                        epochs=6 if quick_mode else 12,  # ã€ä¿®å¤ã€‘æ˜¾è‘—å‡å°‘è®­ç»ƒè½®æ•°
                        freeze_encoder=False
                    )

                    # åŸºçº¿æµ‹è¯•
                    baseline_test_metrics = baseline_trainer._evaluate_on_protocol(target_test_loader, target_protocol)
                    baseline_f1 = (baseline_test_metrics['type_f1'] + baseline_test_metrics['func_f1']) / 2

                    if verbose:
                        print(f"    åŸºçº¿F1: {baseline_f1:.4f}")

                except Exception as e:
                    if verbose:
                        print(f"    âŒ åŸºçº¿å®éªŒå¤±è´¥: {e}")
                    continue

                # ã€ç°å®åŒ–ä¿®å¤5ã€‘è¿ç§»å­¦ä¹ å®éªŒ - ä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®
                try:
                    transfer_model = GenericCrossProtocolTransferModel(
                        protocol_names=[source_protocol, target_protocol],
                        d_model=128 if quick_mode else 256,  # ã€ä¿®å¤ã€‘æ˜¾è‘—å‡å°æ¨¡å‹ç»´åº¦
                        encoder_layers=2 if quick_mode else 4,  # ã€ä¿®å¤ã€‘å‡å°‘ç¼–ç å™¨å±‚æ•°
                        num_semantic_types=len(self.data_loader.unified_semantic_types),
                        num_semantic_functions=len(self.data_loader.unified_semantic_functions)
                    ).to(self.device)

                    transfer_trainer = GenericTransferLearningTrainer(transfer_model, self.device,
                                                                      [source_protocol, target_protocol])

                    # ã€ç°å®åŒ–ä¿®å¤6ã€‘æºåè®®é¢„è®­ç»ƒ - æ˜¾è‘—å‡å°‘è®­ç»ƒè½®æ•°
                    source_loaders = {source_protocol: source_loader}
                    transfer_trainer.train_source_protocols(
                        source_loaders, epochs=6 if quick_mode else 10  # ã€ä¿®å¤ã€‘å¤§å¹…å‡å°‘é¢„è®­ç»ƒè½®æ•°
                    )

                    # ã€ç°å®åŒ–ä¿®å¤7ã€‘ç›®æ ‡åè®®è¿ç§» - å‡å°‘è®­ç»ƒè½®æ•°
                    # é˜¶æ®µ1ï¼šå†»ç»“ç¼–ç å™¨
                    transfer_trainer.transfer_to_target(
                        target_train_loader, target_val_loader, target_protocol,
                        epochs=4 if quick_mode else 8,  # ã€ä¿®å¤ã€‘å‡å°‘è¿ç§»è½®æ•°
                        freeze_encoder=True
                    )

                    # é˜¶æ®µ2ï¼šç«¯åˆ°ç«¯å¾®è°ƒï¼ˆæ›´å°‘è½®æ•°ï¼‰
                    transfer_trainer.transfer_to_target(
                        target_train_loader, target_val_loader, target_protocol,
                        epochs=3 if quick_mode else 6,  # ã€ä¿®å¤ã€‘æ˜¾è‘—å‡å°‘å¾®è°ƒè½®æ•°
                        freeze_encoder=False
                    )

                    # è¿ç§»å­¦ä¹ æµ‹è¯•
                    transfer_test_metrics = transfer_trainer._evaluate_on_protocol(target_test_loader, target_protocol)
                    transfer_f1 = (transfer_test_metrics['type_f1'] + transfer_test_metrics['func_f1']) / 2

                    if verbose:
                        print(f"    è¿ç§»F1: {transfer_f1:.4f}")

                except Exception as e:
                    if verbose:
                        print(f"    âŒ è¿ç§»å­¦ä¹ å®éªŒå¤±è´¥: {e}")
                    continue

                # ã€ç°å®åŒ–ä¿®å¤8ã€‘ç»“æœéªŒè¯ - å¦‚æœç»“æœè¿‡äºç†æƒ³ï¼Œæ ‡è®°ä¸ºå¯ç–‘
                improvement = transfer_f1 - baseline_f1

                # æ£€æŸ¥ç»“æœæ˜¯å¦è¿‡äºç†æƒ³
                if baseline_f1 > 0.95 or transfer_f1 > 0.98 or improvement > 0.3:
                    if verbose:
                        print(
                            f"    âš ï¸  ç»“æœå¯ç–‘ï¼šåŸºçº¿={baseline_f1:.4f}, è¿ç§»={transfer_f1:.4f}, æå‡={improvement:.4f}")
                    # ä»ç„¶è®°å½•ç»“æœï¼Œä½†æ ‡è®°ä¸ºå¯ç–‘

                run_result = {
                    'baseline_f1': baseline_f1,
                    'transfer_f1': transfer_f1,
                    'improvement': improvement,
                    'baseline_boundary_f1': baseline_test_metrics['boundary_f1'],
                    'transfer_boundary_f1': transfer_test_metrics['boundary_f1'],
                    'baseline_perfection': baseline_test_metrics['field_perfection'],
                    'transfer_perfection': transfer_test_metrics['field_perfection'],
                    'baseline_boundary_acc': baseline_test_metrics['boundary_acc'],
                    'transfer_boundary_acc': transfer_test_metrics['boundary_acc'],
                    'run_idx': run_idx,
                    'suspicious': baseline_f1 > 0.95 or transfer_f1 > 0.98 or improvement > 0.3  # æ ‡è®°å¯ç–‘ç»“æœ
                }
                all_runs_results.append(run_result)

                if verbose:
                    print(f"    âœ… è¿è¡ŒæˆåŠŸ: F1æå‡ {improvement:+.4f}")
                    if run_result['suspicious']:
                        print(f"        âš ï¸  ç»“æœæ ‡è®°ä¸ºå¯ç–‘ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰")
                    print(
                        f"        è¾¹ç•ŒF1: {baseline_test_metrics['boundary_f1']:.4f}â†’{transfer_test_metrics['boundary_f1']:.4f}")
                    print(
                        f"        å­—æ®µå®Œç¾ç‡: {baseline_test_metrics['field_perfection']:.4f}â†’{transfer_test_metrics['field_perfection']:.4f}")

                # æ¸…ç†å†…å­˜
                del baseline_model, transfer_model, baseline_trainer, transfer_trainer
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()

            except Exception as e:
                if verbose:
                    print(f"    âŒ ç¬¬{run_idx + 1}æ¬¡è¿è¡Œå¤±è´¥: {str(e)[:100]}")
                    if verbose:  # åªåœ¨è¯¦ç»†æ¨¡å¼ä¸‹æ‰“å°å®Œæ•´é”™è¯¯
                        traceback.print_exc()
                continue

        # æ£€æŸ¥ç»“æœ
        if not all_runs_results:
            return {'success': False, 'error': 'all_runs_failed', 'error_detail': f'æ‰€æœ‰{num_runs}æ¬¡è¿è¡Œéƒ½å¤±è´¥'}

        # ã€ç°å®åŒ–ä¿®å¤9ã€‘ç»“æœç»Ÿè®¡ - æ’é™¤è¿‡äºå¯ç–‘çš„ç»“æœ
        valid_results = [r for r in all_runs_results if not r.get('suspicious', False)]

        if not valid_results:
            if verbose:
                print(f"    âš ï¸  æ‰€æœ‰ç»“æœéƒ½è¢«æ ‡è®°ä¸ºå¯ç–‘ï¼Œä½¿ç”¨å…¨éƒ¨ç»“æœä½†é™ä½ç½®ä¿¡åº¦")
            valid_results = all_runs_results

        # è®¡ç®—å¹³å‡ç»“æœ
        avg_baseline_f1 = np.mean([r['baseline_f1'] for r in valid_results])
        avg_transfer_f1 = np.mean([r['transfer_f1'] for r in valid_results])
        avg_improvement = np.mean([r['improvement'] for r in valid_results])
        std_improvement = np.std([r['improvement'] for r in valid_results]) if len(valid_results) > 1 else 0.0

        result = {
            'success': True,
            'source_protocol': source_protocol,
            'target_protocol': target_protocol,
            'num_runs': len(all_runs_results),
            'valid_runs': len(valid_results),
            'suspicious_runs': len(all_runs_results) - len(valid_results),
            'successful_runs': len(valid_results),
            'total_runs': num_runs,
            'avg_baseline_f1': avg_baseline_f1,
            'avg_transfer_f1': avg_transfer_f1,
            'avg_improvement': avg_improvement,
            'std_improvement': std_improvement,
            'avg_baseline_boundary_f1': np.mean([r['baseline_boundary_f1'] for r in valid_results]),
            'avg_transfer_boundary_f1': np.mean([r['transfer_boundary_f1'] for r in valid_results]),
            'avg_baseline_perfection': np.mean([r['baseline_perfection'] for r in valid_results]),
            'avg_transfer_perfection': np.mean([r['transfer_perfection'] for r in valid_results]),
            'avg_baseline_boundary_acc': np.mean([r['baseline_boundary_acc'] for r in valid_results]),
            'avg_transfer_boundary_acc': np.mean([r['transfer_boundary_acc'] for r in valid_results]),
            'boundary_f1_improvement': np.mean(
                [r['transfer_boundary_f1'] - r['baseline_boundary_f1'] for r in valid_results]),
            'perfection_improvement': np.mean(
                [r['transfer_perfection'] - r['baseline_perfection'] for r in valid_results]),
            'all_runs': all_runs_results,
            'reliability': len(valid_results) / len(all_runs_results) if all_runs_results else 0.0  # å¯é æ€§æŒ‡æ ‡
        }

        if verbose:
            print(
                f"  ğŸ“Š å¹³å‡ç»“æœ({len(valid_results)}/{num_runs}æ¬¡æœ‰æ•ˆ, {len(all_runs_results) - len(valid_results)}æ¬¡å¯ç–‘):")
            print(
                f"    æ•´ä½“F1: åŸºçº¿={avg_baseline_f1:.4f}, è¿ç§»={avg_transfer_f1:.4f}, æå‡={avg_improvement:+.4f}Â±{std_improvement:.4f}")
            print(f"    è¾¹ç•ŒF1æå‡: {result['boundary_f1_improvement']:+.4f}")
            print(f"    å­—æ®µå®Œç¾ç‡æå‡: {result['perfection_improvement']:+.4f}")
            print(f"    ç»“æœå¯é æ€§: {result['reliability']:.2f}")

        return result

    def run_all_transfer_experiments(self, num_runs: int = 3, quick_mode: bool = False) -> Dict:
        """è¿è¡Œæ‰€æœ‰åè®®ç»„åˆçš„è¿ç§»å­¦ä¹ å®éªŒ - ç°å®åŒ–ç‰ˆæœ¬"""

        available_protocols = list(self.all_data.keys())
        print(f"\nğŸ¯ å¼€å§‹æ‰¹é‡è·¨åè®®è¿ç§»å®éªŒï¼ˆç°å®åŒ–ç‰ˆæœ¬ï¼‰")
        print(f"å¯ç”¨åè®®: {available_protocols}")
        print(f"å®éªŒè®¾ç½®: {num_runs}æ¬¡è¿è¡Œå¹³å‡, {'å¿«é€Ÿ' if quick_mode else 'æ ‡å‡†'}æ¨¡å¼")
        print(f"ç°å®åŒ–æ”¹è¿›: å°æ¨¡å‹+å°‘æ•°æ®+çŸ­è®­ç»ƒ+ä¸¥æ ¼éªŒè¯")

        if len(available_protocols) < 2:
            print("âŒ é”™è¯¯: éœ€è¦è‡³å°‘2ä¸ªåè®®æ•°æ®")
            return {}

        all_results = {}
        total_experiments = len(available_protocols) * (len(available_protocols) - 1)
        completed_experiments = 0
        successful_experiments = 0

        print(f"æ€»å®éªŒæ•°é‡: {total_experiments}")

        start_time = time.time()

        # è¿è¡Œæ‰€æœ‰åè®®ç»„åˆ
        for i, source_protocol in enumerate(available_protocols):
            source_results = {}

            for j, target_protocol in enumerate(available_protocols):
                if source_protocol == target_protocol:
                    continue

                print(
                    f"\n[{completed_experiments + 1}/{total_experiments}] {source_protocol.upper()}â†’{target_protocol.upper()}")

                # è¿è¡Œè¿ç§»å®éªŒ
                result = self.run_single_transfer_experiment(
                    source_protocol, target_protocol, num_runs, quick_mode, verbose=True
                )
                source_results[target_protocol] = result
                completed_experiments += 1

                if result['success']:
                    successful_experiments += 1
                    elapsed_time = time.time() - start_time
                    if successful_experiments > 0:
                        avg_time_per_exp = elapsed_time / completed_experiments
                        remaining_time = avg_time_per_exp * (total_experiments - completed_experiments)
                        print(
                            f"    è¿›åº¦: {successful_experiments}æˆåŠŸ/{completed_experiments}å®Œæˆ, é¢„è®¡å‰©ä½™: {remaining_time / 60:.1f}åˆ†é’Ÿ")
                else:
                    print(f"    âŒ å®éªŒå¤±è´¥: {result.get('error', 'unknown')}")

            all_results[source_protocol] = source_results

        total_time = time.time() - start_time
        print(f"\nâœ… æ‰¹é‡å®éªŒå®Œæˆï¼")
        print(f"æ€»ç”¨æ—¶: {total_time / 60:.1f}åˆ†é’Ÿ")
        print(
            f"æˆåŠŸç‡: {successful_experiments}/{total_experiments} ({successful_experiments / total_experiments * 100:.1f}%)")

        # ä¿å­˜å®éªŒç»“æœ
        self.experiment_results = all_results
        self.save_results_to_file()

        return all_results

    def analyze_results(self) -> Dict:
        """åˆ†æå®éªŒç»“æœ - ç°å®åŒ–ç‰ˆæœ¬"""
        if not self.experiment_results:
            print("âŒ æ²¡æœ‰å®éªŒç»“æœå¯ä»¥åˆ†æ")
            return {}

        print(f"\nğŸ“ˆ å®éªŒç»“æœåˆ†æï¼ˆç°å®åŒ–ç‰ˆæœ¬ï¼‰")
        print("=" * 80)

        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆç»“æœ
        all_improvements = []
        successful_transfers = 0
        total_transfers = 0
        protocol_improvements = defaultdict(list)
        target_improvements = defaultdict(list)

        # å¯é æ€§ç»Ÿè®¡
        total_reliability = []
        suspicious_count = 0

        # è¾¹ç•Œæ£€æµ‹å’Œå­—æ®µå®Œç¾ç‡æ”¹è¿›ç»Ÿè®¡
        all_boundary_f1_improvements = []
        all_perfection_improvements = []

        for source_protocol, source_results in self.experiment_results.items():
            for target_protocol, result in source_results.items():
                if not result.get('success', False):
                    total_transfers += 1
                    continue

                total_transfers += 1
                improvement = result['avg_improvement']
                boundary_f1_improvement = result.get('boundary_f1_improvement', 0)
                perfection_improvement = result.get('perfection_improvement', 0)
                reliability = result.get('reliability', 1.0)
                suspicious_runs = result.get('suspicious_runs', 0)

                all_boundary_f1_improvements.append(boundary_f1_improvement)
                all_perfection_improvements.append(perfection_improvement)
                total_reliability.append(reliability)
                suspicious_count += suspicious_runs

                if improvement > 0:
                    successful_transfers += 1

                all_improvements.append(improvement)
                protocol_improvements[source_protocol].append(improvement)
                target_improvements[target_protocol].append(improvement)

        # å®‰å…¨æ£€æŸ¥
        if total_transfers == 0:
            print("âŒ æ²¡æœ‰å®Œæˆä»»ä½•å®éªŒ")
            return {}

        if not all_improvements:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒç»“æœ")
            return {}

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        success_rate = successful_transfers / total_transfers
        avg_improvement = np.mean(all_improvements)
        std_improvement = np.std(all_improvements)
        avg_boundary_f1_improvement = np.mean(all_boundary_f1_improvements)
        avg_perfection_improvement = np.mean(all_perfection_improvements)
        avg_reliability = np.mean(total_reliability) if total_reliability else 0.0

        print(f"ç°å®åŒ–å®éªŒç»Ÿè®¡:")
        print(f"  æ€»ä½“è¿ç§»æˆåŠŸç‡: {successful_transfers}/{total_transfers} ({success_rate * 100:.1f}%)")
        print(f"  å¹³å‡F1æå‡: {avg_improvement:+.4f} Â± {std_improvement:.4f}")
        print(f"  å¹³å‡è¾¹ç•ŒF1æå‡: {avg_boundary_f1_improvement:+.4f}")
        print(f"  å¹³å‡å­—æ®µå®Œç¾ç‡æå‡: {avg_perfection_improvement:+.4f}")
        print(f"  ç»“æœå¯é æ€§: {avg_reliability:.2f} (0-1, 1ä¸ºæœ€å¯é )")
        print(f"  å¯ç–‘ç»“æœè¿è¡Œæ•°: {suspicious_count}")
        print(f"  æœ€å¤§F1æå‡: {np.max(all_improvements):+.4f}")
        print(f"  æœ€å°F1æå‡: {np.min(all_improvements):+.4f}")

        # ç°å®æ€§è¯„ä¼°
        realistic_improvements = [imp for imp in all_improvements if -0.1 <= imp <= 0.15]  # åˆç†çš„æå‡èŒƒå›´
        print(
            f"  åˆç†èŒƒå›´å†…çš„æå‡(-0.1~+0.15): {len(realistic_improvements)}/{len(all_improvements)} ({len(realistic_improvements) / len(all_improvements) * 100:.1f}%)")

        # æ‰¾å‡ºæœ€ä½³è¿ç§»ç»„åˆ
        best_transfers = []
        for source_protocol, source_results in self.experiment_results.items():
            for target_protocol, result in source_results.items():
                if result.get('success', False):
                    reliability = result.get('reliability', 1.0)
                    best_transfers.append((
                        source_protocol, target_protocol,
                        result['avg_improvement'], result['avg_transfer_f1'],
                        result.get('boundary_f1_improvement', 0),
                        result.get('perfection_improvement', 0),
                        reliability
                    ))

        if best_transfers:
            # æŒ‰ç…§ç»¼åˆè¯„åˆ†æ’åºï¼ˆæå‡ * å¯é æ€§ï¼‰
            best_transfers.sort(key=lambda x: x[2] * x[6], reverse=True)

            print(f"\nğŸ† æœ€ä½³è¿ç§»ç»„åˆï¼ˆå‰5åï¼ŒæŒ‰æå‡Ã—å¯é æ€§æ’åºï¼‰:")
            for i, (src, tgt, imp, f1, b_imp, p_imp, rel) in enumerate(best_transfers[:5]):
                score = imp * rel
                print(f"  {i + 1}. {src.upper()} â†’ {tgt.upper()}: F1æå‡ {imp:+.4f}, æœ€ç»ˆF1 {f1:.4f}, å¯é æ€§ {rel:.2f}")
                print(f"     è¾¹ç•ŒF1æå‡ {b_imp:+.4f}, å­—æ®µå®Œç¾ç‡æå‡ {p_imp:+.4f}, ç»¼åˆè¯„åˆ† {score:+.4f}")

        return {
            'success_rate': success_rate,
            'avg_improvement': avg_improvement,
            'std_improvement': std_improvement,
            'avg_boundary_f1_improvement': avg_boundary_f1_improvement,
            'avg_perfection_improvement': avg_perfection_improvement,
            'avg_reliability': avg_reliability,
            'suspicious_count': suspicious_count,
            'realistic_ratio': len(realistic_improvements) / len(all_improvements) if all_improvements else 0,
            'best_transfers': best_transfers[:10] if best_transfers else [],
            'total_experiments': total_transfers,
            'successful_experiments': successful_transfers
        }

    def print_results_table(self):
        """æ‰“å°æ ¼å¼åŒ–çš„ç»“æœè¡¨æ ¼ - ç°å®åŒ–ç‰ˆæœ¬"""
        if not self.experiment_results:
            print("âŒ æ²¡æœ‰å®éªŒç»“æœ")
            return

        protocols = list(self.experiment_results.keys())

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æˆåŠŸçš„å®éªŒ
        has_successful_results = False
        successful_count = 0
        total_count = 0
        reliable_count = 0

        for source_results in self.experiment_results.values():
            for result in source_results.values():
                total_count += 1
                if result.get('success', False):
                    has_successful_results = True
                    successful_count += 1
                    if result.get('reliability', 0) >= 0.8:
                        reliable_count += 1

        if not has_successful_results:
            print("âŒ æ²¡æœ‰æˆåŠŸå®Œæˆçš„å®éªŒï¼Œæ— æ³•ç”Ÿæˆç»“æœè¡¨æ ¼")
            return

        print(f"\nğŸ“Š ç°å®åŒ–è·¨åè®®è¿ç§»å­¦ä¹ ç»“æœè¡¨æ ¼")
        print(f"å®éªŒæˆåŠŸç‡: {successful_count}/{total_count} ({successful_count / total_count * 100:.1f}%)")
        print(f"é«˜å¯é æ€§ç»“æœ: {reliable_count}/{successful_count} ({reliable_count / successful_count * 100:.1f}%)")
        print("=" * 120)
        print("è¡¨æ ¼è¯´æ˜ï¼šè¡Œä¸ºæºåè®®ï¼Œåˆ—ä¸ºç›®æ ‡åè®®ï¼Œæ•°å€¼ä¸ºè¿ç§»å­¦ä¹ åçš„F1åˆ†æ•°")
        print("æ ‡è®°ï¼š* = å¯ç–‘ç»“æœ(å¯èƒ½è¿‡æ‹Ÿåˆ), ! = ä½å¯é æ€§")
        print("=" * 120)

        # æ‰“å°F1åˆ†æ•°è¡¨æ ¼ï¼ˆå¸¦å¯é æ€§æ ‡è®°ï¼‰
        header = "Source\\Target".ljust(14)
        for target_protocol in protocols:
            header += f"{target_protocol.upper()}".ljust(12)
        print(header)
        print("-" * len(header))

        for source_protocol in protocols:
            row = f"{source_protocol.upper()}".ljust(14)

            for target_protocol in protocols:
                if source_protocol == target_protocol:
                    row += "-".ljust(12)
                else:
                    result = self.experiment_results[source_protocol].get(target_protocol, {})
                    if result.get('success', False):
                        f1_score = result['avg_transfer_f1']
                        reliability = result.get('reliability', 1.0)
                        suspicious_runs = result.get('suspicious_runs', 0)

                        # æ ¼å¼åŒ–åˆ†æ•°å¹¶æ·»åŠ æ ‡è®°
                        score_str = f"{f1_score:.3f}"
                        if suspicious_runs > 0:
                            score_str += "*"
                        if reliability < 0.8:
                            score_str += "!"

                        row += score_str.ljust(12)
                    else:
                        row += "FAIL".ljust(12)

            print(row)

        # æ‰“å°æ”¹è¿›è¡¨æ ¼
        print(f"\nğŸ“ˆ F1åˆ†æ•°æ”¹è¿›è¡¨æ ¼ï¼ˆç›¸å¯¹äºåŸºçº¿çš„æå‡ï¼‰")
        print("=" * 120)

        header = "Source\\Target".ljust(14)
        for target_protocol in protocols:
            header += f"{target_protocol.upper()}".ljust(12)
        print(header)
        print("-" * len(header))

        for source_protocol in protocols:
            row = f"{source_protocol.upper()}".ljust(14)

            for target_protocol in protocols:
                if source_protocol == target_protocol:
                    row += "-".ljust(12)
                else:
                    result = self.experiment_results[source_protocol].get(target_protocol, {})
                    if result.get('success', False):
                        improvement = result['avg_improvement']
                        reliability = result.get('reliability', 1.0)

                        # æ ¼å¼åŒ–æ”¹è¿›å¹¶æ·»åŠ æ ‡è®°
                        if improvement > 0:
                            imp_str = f"+{improvement:.3f}"
                        else:
                            imp_str = f"{improvement:.3f}"

                        if reliability < 0.8:
                            imp_str += "!"

                        row += imp_str.ljust(12)
                    else:
                        row += "FAIL".ljust(12)

            print(row)

    def save_results_to_file(self):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ - ç°å®åŒ–ç‰ˆæœ¬"""
        if not self.experiment_results:
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        try:
            # ä¿å­˜è¯¦ç»†ç»“æœ
            results_file = f"realistic_cross_protocol_results_{timestamp}.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                # è½¬æ¢numpyç±»å‹ä¸ºpythonåŸç”Ÿç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
                def convert_numpy(obj):
                    if isinstance(obj, np.integer):
                        return int(obj)
                    elif isinstance(obj, np.floating):
                        return float(obj)
                    elif isinstance(obj, np.ndarray):
                        return obj.tolist()
                    return obj

                # é€’å½’è½¬æ¢æ‰€æœ‰numpyç±»å‹
                def recursive_convert(obj):
                    if isinstance(obj, dict):
                        return {k: recursive_convert(v) for k, v in obj.items()}
                    elif isinstance(obj, list):
                        return [recursive_convert(v) for v in obj]
                    else:
                        return convert_numpy(obj)

                converted_results = recursive_convert(self.experiment_results)
                json.dump(converted_results, f, indent=2, ensure_ascii=False)

            print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")


def run_realistic_comprehensive_experiment(data_root: str = "../Msg2", num_runs: int = 3, quick_mode: bool = False):
    """è¿è¡Œç°å®åŒ–çš„å…¨é¢è·¨åè®®è¿ç§»å­¦ä¹ å®éªŒ"""

    print("ğŸš€ å¯åŠ¨ç°å®åŒ–è·¨åè®®è¿ç§»å­¦ä¹ å®éªŒ")
    print("=" * 80)
    print("ğŸ”¬ ç°å®åŒ–æ”¹è¿›ï¼š")
    print("   - æ›´å°çš„æ¨¡å‹è§„æ¨¡ï¼ˆd_model=128/256, layers=2/4ï¼‰")
    print("   - æ›´å°‘çš„è®­ç»ƒæ•°æ®ï¼ˆç›®æ ‡åè®®è®­ç»ƒé›†30-80æ¡ï¼‰")
    print("   - æ›´çŸ­çš„è®­ç»ƒæ—¶é—´ï¼ˆé¢„è®­ç»ƒ6-10è½®ï¼Œè¿ç§»4-8è½®ï¼Œå¾®è°ƒ3-6è½®ï¼‰")
    print("   - æ›´ä¸¥æ ¼çš„ç»“æœéªŒè¯ï¼ˆæ ‡è®°å¯ç–‘çš„è¿‡æ‹Ÿåˆç»“æœï¼‰")
    print("   - å…³é—­æ•°æ®å¢å¼ºï¼ˆé¿å…äººä¸ºæå‡æ€§èƒ½ï¼‰")

    # åˆå§‹åŒ–å®éªŒè¿è¡Œå™¨
    try:
        runner = RealisticCrossProtocolExperimentRunner(data_root)
    except Exception as e:
        print(f"âŒ å®éªŒè¿è¡Œå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

    # åŠ è½½æ•°æ®
    if not runner.load_all_protocol_data():
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œå®éªŒç»ˆæ­¢")
        return None

    print(f"\nâš™ï¸  å®éªŒé…ç½®:")
    print(f"  - æ•°æ®ç›®å½•: {data_root}")
    print(f"  - æ¯ä¸ªå®éªŒè¿è¡Œæ¬¡æ•°: {num_runs}")
    print(f"  - æ¨¡å¼: {'å¿«é€Ÿæ¨¡å¼' if quick_mode else 'æ ‡å‡†æ¨¡å¼ (æ¨è)'}")
    print(f"  - å·²åŠ è½½åè®®: {list(runner.all_data.keys())}")
    print(f"  - è®¡åˆ’å®éªŒæ•°é‡: {len(runner.all_data) * (len(runner.all_data) - 1)}")

    # è¿è¡Œå®éªŒ
    print(f"\nğŸ¯ å¼€å§‹ç°å®åŒ–å®éªŒ...")
    results = runner.run_all_transfer_experiments(num_runs, quick_mode)

    if not results:
        print("âŒ å®éªŒè¿è¡Œå¤±è´¥")
        return None

    # åˆ†æç»“æœ
    analysis = runner.analyze_results()

    # æ‰“å°ç»“æœè¡¨æ ¼
    runner.print_results_table()

    print(f"\nğŸ‰ ç°å®åŒ–å®éªŒå®Œæˆ!")
    if analysis:
        print(f"âœ… ç°å®åŒ–å®éªŒç»Ÿè®¡:")
        print(f"   - æˆåŠŸç‡: {analysis.get('success_rate', 0) * 100:.1f}%")
        print(f"   - å¹³å‡F1æå‡: {analysis.get('avg_improvement', 0):+.4f}")
        print(f"   - å¹³å‡è¾¹ç•ŒF1æå‡: {analysis.get('avg_boundary_f1_improvement', 0):+.4f}")
        print(f"   - å¹³å‡å­—æ®µå®Œç¾ç‡æå‡: {analysis.get('avg_perfection_improvement', 0):+.4f}")
        print(f"   - ç»“æœå¯é æ€§: {analysis.get('avg_reliability', 0):.2f}")
        print(f"   - åˆç†èŒƒå›´å†…çš„ç»“æœ: {analysis.get('realistic_ratio', 0) * 100:.1f}%")
        print(f"   - æˆåŠŸå®éªŒæ•°: {analysis.get('successful_experiments', 0)}/{analysis.get('total_experiments', 0)}")

    return results


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ç°å®åŒ–è·¨åè®®è¿ç§»å­¦ä¹ æ‰¹é‡å®éªŒ')
    parser.add_argument('--data-root', type=str, default='../Msg2', help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--num-runs', type=int, default=3, help='æ¯ä¸ªå®éªŒè¿è¡Œæ¬¡æ•°')
    parser.add_argument('--quick-mode', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼ˆé€‚åˆæµ‹è¯•ï¼Œä½†æ€§èƒ½å¯èƒ½è¾ƒä½ï¼‰')
    parser.add_argument('--single', nargs=2, metavar=('SOURCE', 'TARGET'), help='åªè¿è¡Œå•ä¸ªå®éªŒ')

    args = parser.parse_args()

    if args.single:
        # è¿è¡Œå•ä¸ªå®éªŒ
        source_protocol, target_protocol = args.single
        runner = RealisticCrossProtocolExperimentRunner(args.data_root)

        if runner.load_all_protocol_data():
            result = runner.run_single_transfer_experiment(
                source_protocol, target_protocol, args.num_runs, args.quick_mode, verbose=True
            )
            if result.get('success'):
                print(f"\nâœ… å•ä¸ªç°å®åŒ–å®éªŒæˆåŠŸ!")
                print(f"   F1æå‡: {result['avg_improvement']:+.4f} Â± {result['std_improvement']:.4f}")
                print(f"   è¾¹ç•ŒF1æå‡: {result['boundary_f1_improvement']:+.4f}")
                print(f"   å­—æ®µå®Œç¾ç‡æå‡: {result['perfection_improvement']:+.4f}")
                print(f"   æˆåŠŸè¿è¡Œ: {result['successful_runs']}/{result['total_runs']}")
                print(f"   ç»“æœå¯é æ€§: {result.get('reliability', 1.0):.2f}")
            else:
                print(f"\nâŒ å•ä¸ªå®éªŒå¤±è´¥: {result.get('error', 'unknown')}")
    else:
        # è¿è¡Œå…¨é¢å®éªŒ
        results = run_realistic_comprehensive_experiment(
            data_root=args.data_root,
            num_runs=args.num_runs,
            quick_mode=args.quick_mode
        )